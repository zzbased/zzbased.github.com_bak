<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>机器学习领域的会议与期刊</title>
  <meta name="description" content="机器学习，最近几年来，随着大数据与深度学习的兴起，越来越火。身为工业界的一线小卒，不求闻达于顶级牛会，但求从大拿们的论文中吸取有用的知识，将其运用到工业界，为公司广告收入的增长添砖加瓦。">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yourdomain.com/2014/03/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BC%9A%E8%AE%AE%E4%B8%8E%E6%9C%9F%E5%88%8A.html">
  <link rel="alternate" type="application/rss+xml" title="100的技术博客" href="http://yourdomain.com/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">100的技术博客</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">机器学习领域的会议与期刊</h1>
    <p class="post-meta">Mar 15, 2014</p>
  </header>

  <article class="post-content">
    <p>机器学习，最近几年来，随着大数据与深度学习的兴起，越来越火。身为工业界的一线小卒，不求闻达于顶级牛会，但求从大拿们的论文中吸取有用的知识，将其运用到工业界，为公司广告收入的增长添砖加瓦。</p>

<p>那么，机器学习领域，有哪些牛会和牛刊呢？下面简单陈列下：</p>

<h2 id="section">机器学习期刊</h2>

<h3 id="section-1">计算机科学</h3>

<p>计算机科学的publication最大特点在于：极度重视会议，而期刊则通常只用来做re-publication。大部分期刊文章都是会议论文的扩展版，首发就在期刊上的相对较少。也正因为如此，计算机期刊的影响因子都低到惊人的程度，顶级刊物往往也只有1到2左右—-被引的通常都是会议版论文，而不是很久以后才出版的期刊版。因此，要讨论计算机科学的publication，首先必须强调的一点是totally forget about IF。</p>

<p>另外一点要强调的事，计算机科学的绝大多数期刊和大部分的“好”会议都规模非常有限。很多好的期刊一期只登十来篇甚至三四篇论文，有的还是季刊或双月刊。很多好的会议每年只录用三四十篇甚至二十篇左右的论文。所以，当你发现计算机的每个领域都有好几种顶级刊物和好几个顶级会议，不必惊讶。</p>

<p>整个计算机科学中最好的期刊为Journal of the ACM(JACM)。此刊物为ACM的官方学刊，受到最广泛的尊敬。但由于该刊宣称它只刊登那些对计算机科学有长远影响的论文，因此其不可避免地具有理论歧视（theory bias）。事实上确实如此：尽管JACM征稿范围包括了计算机的绝大部分领域，然而其刊登的论文大部分都是算法、复杂度、图论、组合数学等纯粹理论的东西，其它领域的论文要想进入则难如登天。</p>

<p>另外一份在计算机科学领域有重大影响的刊物为Communications of the ACM (CACM)。从某种意义上来说，CACM比JACM要像Nature/Science很多。JACM上登的全是长篇大论，满纸的定义、定理和证明，别说一般读者没法看，就连很相近的领域的专家都未必能看懂。而CACM则是magazine，既登高水平的学术论文和综述，也登各种科普性质的文章和新闻。即便是论文，CACM也要求文章必须通俗易懂，不追求数学上的严格证明，而追求易于理解的直觉描述。在十几二十年前，CACM的文章几乎都是经典。但最近几年，由于CACM进一步通俗化，其学术质量稍有下降。</p>

<p>IEEE Transaction on Computers为IEEE在计算机方面最好的刊物。但由于IEEE的特点，其更注重computer engineering而非computer science。换句话说，IEEE Transaction on Computers主要登载systems, architecture, hardware等领域的东西，尽管它的范围已经比大部分刊物要广泛。</p>

<p>就刊物的质量而言，ACM Transactions系列总体来讲都高于IEEE Transactions系列，不过也不可一概而论。大部分ACM Transactions都是本领域最好的刊物或最好的刊物之一。大部分IEEE Transactions都是本领域很好的刊物，但也有最好的或者一般的。</p>

<p>IEEE和ACM是两个独立组织。SIG是ACM旗下的“兴趣小组” (Special Interests Group)，所以很多由ACM某个兴趣小组（比如KDD）主板的会，就会冠以SIG-KDD的名号。</p>

<p>非ACM/IEEE的刊物中，也有好的甚至最好的。例如，SIAM Journal on Computing被认为是理论方面最好的期刊之一。</p>

<h3 id="section-2">机器学习</h3>

<p>在学术期刊方面，最好的应该是AI Journal和IEEE TPAMI，在杂志方面，最好的是AI Magazine。一般认为最高刊物是AI Journal（即Artificial Intelligence)，因为它创刊早，声誉高。但AI Journal以前完全偏重于基于符号化建模的研究，大量文章都是非单调推理等方面的，其他的新兴领域尤其是基于实验方法学的领域想有文章简直难于登天。但最近几年，该刊基调有点转变，计算智能等新领域的文章也开始出现了，实验方法学也开始被接受。TPAMI的声誉也很高，但其范围更局限，几乎完全放在模式识别及相关领域上，而且即使是模式识别，语音方面也几乎不包含。因此更恰当地说，TPAMI是模式识别的最高刊物。如果说AI Journal相当于JACM，那么AI Magazine就相当于CACM。</p>

<p>和AI方面的会议一样，一些壮大起来的子领域也有自己的顶级刊物，象机器学习的Machine Learning，神经计算的Neural Computation，视觉的IJCV等。其他一流但非顶级的刊物主要包括JAIR、IEEE Trans中相关的刊物等等。</p>

<h2 id="section-3">机器学习会议</h2>

<p>机器学习顶级会议：NIPS, ICML, UAI, AISTATS; （期刊：JMLR, ML, Trends in ML, IEEE T-NN）；
计算机视觉和图像识别：ICCV, CVPR, ECCV;（期刊：IEEE T-PAMI, IJCV, IEEE T-IP）；
人工智能：IJCAI, AAAI; （期刊AI）；
另外相关的还有SIGRAPH, KDD, ACL, SIGIR, WWW等；
特别是，如果做机器学习，必须地，把近4年的NIPS, ICML翻几遍；如果做计算机视觉，要把近4年的ICCV, CVPR, NIPS, ICML翻几遍；</p>

<p>computer vision(cv) 存在ICCV/CVPR/ECCV三个顶级会议，它们档次差不多，都应该在一流会议行列</p>

<p>IJCAI (1+): AI最好的综合性会议, 1969年开始, 每两年开一次, 奇数年开. 因为AI 实在太大, 所以虽然每届基本上能录100多篇（现在已经到200多篇了），但分到每个 领域就没几篇了，象machine learning、computer vision这么大的领域每次大概也 就10篇左右, 所以难度很大. 不过从录用率上来看倒不太低,基本上20%左右, 因为内 行人都会掂掂分量, 没希望的就别浪费reviewer的时间了. 最近中国大陆投往国际会 议的文章象潮水一样, 而且因为国内很少有能自己把关的研究组, 所以很多会议都在 complain说中国的低质量文章严重妨碍了PC的工作效率. 在这种情况下, 估计这几年 国际会议的录用率都会降下去. 另外, 以前的IJCAI是没有poster的, 03年开始, 为了 减少被误杀的好人, 增加了2页纸的poster.值得一提的是, IJCAI是由貌似一个公司 的”IJCAI Inc.”主办的(当然实际上并不是公司, 实际上是个基金会), 每次会议上要 发几个奖, 其中最重要的两个是IJCAI Research Excellence Award 和 Computer &amp; Thoughts Award, 前者是终身成就奖, 每次一个人, 基本上是AI的最高奖(有趣的是, 以AI为主业拿图灵奖的6位中, 有2位还没得到这个奖), 后者是奖给35岁以下的 青年科学家, 每次一个人. 这两个奖的获奖演说是每次IJCAI的一个重头戏.另外, IJCAI 的 PC member 相当于其他会议的area chair, 权力很大, 因为是由PC member 去找 reviewer 来审, 而不象一般会议的PC member其实就是 reviewer. 为了制约 这种权力, IJCAI的审稿程序是每篇文章分配2位PC member, primary PC member去找 3位reviewer, second PC member 找一位.</p>

<p>AAAI (1): 美国人工智能学会AAAI的年会. 是一个很好的会议, 但其档次不稳定, 可以给到1+, 也可以给到1-或者2+, 总的来说我给它”1″. 这是因为它的开法完全受 IJCAI制约: 每年开, 但如果这一年的 IJCAI在北美举行, 那么就停开. 所以, 偶数年里因为没有IJCAI, 它就是最好的AI综合性会议, 但因为号召力毕竟比IJCAI要小一些,特别是欧洲人捧AAAI场的比IJCAI少得多(其实亚洲人也是), 所以比IJCAI还是要稍弱一点, 基本上在1和1+之间; 在奇数年, 如果IJCAI不在北美, AAAI自然就变成了比IJCAI低一级的会议(1-或2+), 例如2005年既有IJCAI又有AAAI, 两个会议就进行了协 调, 使得IJCAI的录用通知时间比AAAI的deadline早那么几天, 这样IJCAI落选的文章 可以投往AAAI.在审稿时IJCAI 的 PC chair也在一直催, 说大家一定要快, 因为AAAI那边一直在担心IJCAI的录用通知出晚了AAAI就麻烦了.</p>

<p>COLT (1): 这是计算学习理论最好的会议, ACM主办, 每年举行. 计算学习理论基本上可以看成理论计算机科学和机器学习的交叉,   所以这个会被一些人看成是理论计算 机科学的会而不是AI的会. 我一个朋友用一句话对它进行了精彩的刻画: “一小群数 学家在开会”. 因为COLT的领域比较小, 所以每年会议基本上都是那些人. 这里顺便提一件有趣的事, 因为最近国内搞的会议太多太滥, 而且很多会议都是LNCS/LNAI出论文集, LNCS/LNAI基本上已经被搞臭了, 但很不幸的是, LNCS/LNAI中有一些很好的会议, 例如COLT.</p>

<p>CVPR (1): 计算机视觉和模式识别方面最好的会议之一, IEEE主办, 每年举行. 虽然题目上有计算机视觉, 但个人认为它的模式识别味道更重一些. 事实上它应该是模式识别最好的会议, 而在计算机视觉方面, 还有ICCV与之相当. IEEE一直有个倾向, 要把会办成”盛会”, 历史上已经有些会被它从quality很好的会办成”盛会”了. CVPR搞不好也要走这条路. 这几年录的文章已经不少了. 最近负责CVPR会议的TC的chair发信说, 对这个community来说, 让好人被误杀比被坏人漏网更糟糕, 所以我们是不是要减少好人被误杀的机会啊? 所以我估计明年或者后年的CVPR就要扩招了.</p>

<p>ICCV (1): 介绍CVPR的时候说过了, 计算机视觉方面最好的会之一. IEEE主办, 每年举行.</p>

<p>ICML (1): 机器学习方面最好的会议之一. 现在是IMLS主办, 每年举行. 参见关于NIPS的介绍.</p>

<p>NIPS (1): 神经计算方面最好的会议之一, NIPS主办, 每年举行. 值得注意的是, 这个会每年的举办地都是一样的, 以前是美国丹佛, 现在是加拿大温哥华; 而且它是年底开会, 会开完后第2年才出论文集, 也就是说, NIPS’05的论文集是06年出. 会议的名字“Advances in Neural Information Processing Systems”, 所以, 与ICML\ECML这样 的”标准的”机器学习会议不同, NIPS里有相当一部分神经科学的内容, 和机器学习有一定的距离. 但由于会议的主体内容是机器学习, 或者说与机器学习关系紧密, 所以不少人把NIPS看成是机器学习方面最好的会议之一. 这个会议基本上控制在Michael Jordan的徒子徒孙手中, 所以对Jordan系的人来说, 发NIPS并不是难事, 一些未必很强的工作也能发上去, 但对这个圈子之外的人来说, 想发一篇实在很难, 因为留给”外人”的口子很小. 所以对Jordan系以外的人来说, 发NIPS的难度比ICML更大. 换句话说, ICML比较开放, 小圈子的影响不象NIPS那么大, 所以北美和欧洲人都认, 而NIPS则有些人(特别是一些欧洲人, 包括一些大家)坚决不投稿. 这对会议本身当然并不是好事, 但因为Jordan系很强大, 所以它似乎也不太care. 最近IMLS(国际机器学习学会)改选理事, 有资格提名的人包括近三年在ICML\ECML\COLT发过文章的人, NIPS则被排除在外了. 无论如何, 这是一个非常好的会.</p>

<p>ACL (1-): 计算语言学/自然语言处理方面最好的会议, ACL(Association of Computational Linguistics)主办, 每年开.</p>

<p>KR (1-): 知识表示和推理方面最好的会议之一, 实际上也是传统AI(即基于逻辑的AI) 最好的会议之一. KR Inc.主办, 现在是偶数年开.</p>

<p>SIGIR (1-): 信息检索方面最好的会议, ACM主办, 每年开. 这个会现在小圈子气越来越重. 信息检索应该不算AI, 不过因为这里面用到机器学习越来越多, 最近几年甚至 有点机器学习应用会议的味道了, 所以把它也列进来.</p>

<p>SIGKDD (1-): 数据挖掘方面最好的会议, ACM主办, 每年开. 这个会议历史比较短, 毕竟, 与其他领域相比,数据挖掘还只是个小弟弟甚至小侄儿. 在几年前还很难把它列 在tier-1里面, 一方面是名声远不及其他的 top conference响亮, 另一方面是相对容易被录用. 但现在它被列在tier-1应该是毫无疑问的事情了.</p>

<p>UAI (1-): 名字叫”人工智能中的不确定性”, 涉及表示\推理\学习等很多方面, AUAI(Association of UAI) 主办, 每年开.</p>

<h2 id="section-4">参考链接</h2>

<p><a href="http://www.52cs.org/?p=188">周志华点评 机器学习会议</a></p>

<p><a href="http://www.zhihu.com/question/20224890">机器学习领域有哪些著名的期刊和会议</a></p>

<p><a href="http://emuch.net/html/201012/2659795.html">为什么不去读顶级会议上的论文？适应于机器学习、计算机视觉和人工智能</a></p>

<p><a href="http://blog.sciencenet.cn/blog-261330-598758.html">机器学习期刊会议比较</a></p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">100的技术博客</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <li>100的技术博客</li>
          <li><a href="mailto:zero_based@foxmail.com">zero_based@foxmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/zzbased">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">zzbased</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/zero_based">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">zero_based</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text">机器学习，自然语言处理，计算广告学，工作与生活，总结与温习
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
