<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>100的技术博客</title>
    <description>机器学习，自然语言处理，计算广告学，工作与生活，总结与温习
</description>
    <link>http://yourdomain.com/</link>
    <atom:link href="http://yourdomain.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 12 Apr 2015 19:17:10 +0800</pubDate>
    <lastBuildDate>Sun, 12 Apr 2015 19:17:10 +0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Aggregation模型</title>
        <description>&lt;h1 id=&quot;aggregation&quot;&gt;Aggregation模型(集成学习)&lt;/h1&gt;

&lt;h4 id=&quot;author-vincentyaotencentcom&quot;&gt;author: vincentyao@tencent.com&lt;/h4&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;section&quot;&gt;开篇&lt;/h2&gt;

&lt;p&gt;Aggregation模型，即融合式的模型，也叫Ensemble Learning。那什么是Aggregation模型呢？通俗的讲，就是多算法融合。它的思想相当简单直接，以至于用一句俗语就可以完美概括：三个臭皮匠，顶个诸葛亮。实际操作中，Aggregation模型把大大小小的多种算法融合在一起，共同协作来解决一个问题。这些算法可以是不同的算法，也可以是相同的算法。&lt;/p&gt;

&lt;p&gt;根据融合的方式，我们可以将Aggregation模型分为三种：(1)Uniform，将多个模型平均的合并在一起；(2)Linear组合，将多个模型利用linear model融合起来；(3)Conditional，不同的情形使用不同的模型，即将多个模型利用non-linear model融合起来。&lt;/p&gt;

&lt;p&gt;在下文中，我们用g_t 表示第t个单模型，Aggregation model所要做的就是把多个g_t 融合起来。而融合的过程，我们又可以分为两类：(1)Blending，已知多个g_t，再将多个g_t 融合起来，即aggregation after getting g_t；(2)Learning: 一边学习g_t，一边合并多个g_t，即aggregation as well as getting g_t。&lt;/p&gt;

&lt;p&gt;所以，对Aggregation模型基本的划分，则如下表所示。其中，对每一种融合类型，都列举了一种典型的Aggregation模型。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Aggregation Type&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Blending(已知g，再融合多个g)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Learning(一边学习g，一边融合多个g)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;uniform&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;voting/averaging&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Bagging&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;non-uniform&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;linear&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;AdaBoost，GradientBoost&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;conditional&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stacking(non-linear)&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Decision Tree&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;有了多种Aggregation模型后，还可以将Aggregation模型再融合。如果将bagging配上decision tree，则是random forest。如果将AdaBoost配上Decision Tree，则是AdaBoost-DTree。如果将GradientBoost配上Decision Tree，则是大名鼎鼎的GBDT(Gradient Boost Decision Tree)。&lt;/p&gt;

&lt;p&gt;OK，对Aggregation模型有了大体的认识后，下文将来讲述比较具有代表性的Aggregation模型。本文大致分为五个部分：第一部分介绍Decision Tree；第二部分介绍Random forest；第三部分介绍AdaBoost；第四部分介绍Gradient Boost Decision Tree；最后对Aggregation模型再做一下对比与总结。&lt;/p&gt;

&lt;h2 id=&quot;decision-tree&quot;&gt;Decision Tree(决策树)&lt;/h2&gt;

&lt;p&gt;按照Aggregation的方式，可以将决策树的表达式写为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G(x)=\sum_{t=1}^T{q_t(x).g_t(x)}&lt;/script&gt;

&lt;p&gt;g_t表示一个base hypothesis，在决策树里，也就是每条路径的叶子节点。q_t表示条件，表示输入x 是不是在path t上。下图是一个决策树的例子，图中有5个叶子节点，则有5个g_t。通常情况下，我们都用递归形式来表示一个决策树。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/decision_tree_recursive_view.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一棵树的训练过程为：根据一个指标，分裂训练集为几个子集。这个过程不断的在产生的子集里重复递归进行，即递归分割。当一个训练子集的类标都相同时递归停止。这种决策树的自顶向下归纳 (TDITD)是贪心算法的一种, 也是目前为止最为常用的一种训练方法，但不是唯一的方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/decision_tree_train_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从decision tree的训练过程可以看到，训练的关键点是branching(即在每一步选择一个最好的属性来分裂)。那如何branching呢，通常的做法是：Split training set at “the best value” of “the best feature”。”最好”的定义是使得子节点中的训练集尽量的纯，不同的算法使用不同的指标来定义”最好”。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Information gain (ratio)：信息增益是用来衡量样本集S下属性A分裂时的信息熵减少量。信息增益是信息熵的有效减少量，值越高，说明失去的不确定性越多，那么它就应该越早作为决策的依据属性。&lt;/li&gt;
  &lt;li&gt;Gini index：基尼不纯度表示一个随机选中的样本在子集中被分错的可能性。基尼不纯度为这个样本被选中的概率乘以它被分错的概率。当一个节点中所有样本都是一个类时，基尼不纯度为零。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据决策树的输出y的类型，可以将decision tree分为：分类树和回归树。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;分类树：预测分类标签；例如C4.5，选择划分成两个分支后熵最大的feature；&lt;/li&gt;
  &lt;li&gt;回归树：预测实数值；回归树的结果是可以累加的；最小化均方差；&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cart&quot;&gt;CART&lt;/h3&gt;

&lt;p&gt;CART全称”Classification and Regression Tree”，是一种较常用的决策树。为了简化决策过程，它有两个基本选择：(1)二叉树；(2)g_t(x)输出是一个常数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/cart_two_choices.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CART的branch利用Impurity function来衡量。如果目标是回归，利用regression error作为Impurity function。如果目标是分类，利用Gini index作为impurity function。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/cart_impurity_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;利用&lt;a href=&quot;http://mydisk.com/yzlv/webpage/datamining/xiti.html&quot;&gt;利用信息增益，决策树算法的计算过程演示&lt;/a&gt;的例子，如果采用Gini系数的话，计算过程为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;按性别属性变量进行分裂。9/20&lt;em&gt;(1- (6/9)^2 - (3/9)^2) + 11/20&lt;/em&gt;(1- (7/11)^2 - (4/11)^2) = 0.4545。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;按车型变量进行分裂(运动 vs 豪华+家用)。9/20&lt;em&gt;(1- (1/9)^2 - (8/9)^2) + 11/20&lt;/em&gt;(1 - (11/11)^2) = 0.088。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CART的termination条件是：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/CART_termination.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，总结下来，CART是：fully-grown tree with constant leaves that come from bi-branching by purifying。&lt;/p&gt;

&lt;p&gt;关于CART算法的演算过程，可以参考：&lt;a href=&quot;http://www.academia.edu/7032069/An_example_of_calculating_gini_gain_in_CART&quot;&gt;An example of calculating gini gain in CART&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;一个fully-grown的CART，在训练数据上可以做到无差错(即Ein=0)，但这样往往是过拟合的。所以需要regularizer，通常的方法是：限制叶子节点的个数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/CART_regularizer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;decision-tree-1&quot;&gt;Decision tree小结&lt;/h3&gt;
&lt;p&gt;Decision tree优点：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(1)易于理解和解释；(2)即可以处理数值型数据也可以处理类别型数据；(3)生成的模式简单，对噪声数据有很好的健壮性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Decision tree缺点：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(1)启发式的规则(前人的巧思)，缺乏理论基础，并且启发式规则很多，需要selection；(2)容易过拟合；(3)对那些有类别型属性的数据, 信息增益会有一定的偏置；(4)训练一棵最优的决策树是一个完全NP问题。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;几种决策树算法的区别：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ID3算法使用信息增益。C4.5算法是在ID3算法的基础上采用&lt;strong&gt;信息增益率&lt;/strong&gt;的方法选择测试属性。
ID3算法和C4.5算法虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但其生成的决策树分支较大，规模较大。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;为了简化决策树的规模，提高生成决策树的效率，又出现了根据GINI系数来选择测试属性的决策树算法CART。
CART算法采用一种二分递归分割的技术，与基于信息熵的算法不同，CART算法对每次样本集的划分计算GINI系数，GINI系数，GINI系数越小则划分越合理。CART算法总是将当前样本集分割为两个子样本集，使得生成的决策树的每个非叶结点都只有两个分枝。因此CART算法生成的决策树是结构简洁的二叉树。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;更多参考资料&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.raychase.net/1275&quot;&gt;使用ID3算法构造决策树&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.raychase.net/1951&quot;&gt;C4.5&amp;amp; CART&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.autonlab.org/tutorials/dtree.html&quot;&gt;Decision Trees Tutorial by Andrew Moore&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Decision_tree_learning&quot;&gt;Wiki: Decision tree learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pages.cs.wisc.edu/~jerryzhu/cs540/handouts/dt.pdf&quot;&gt;Machine Learning: Decision Trees.CS540&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;random-forest&quot;&gt;Random forest&lt;/h2&gt;

&lt;h3 id=&quot;bagging&quot;&gt;Bagging&lt;/h3&gt;

&lt;p&gt;开篇里已经简要介绍过uniform aggregation。在uniform融合过程中，diversity非常重要，可以利用多个不同的模型，可以用一个模型但不同的参数，可以采用不同的随机值初始化模型，可以随机抽样数据来训练多个模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/bagging_diversity.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bagging(也称bootstrap aggregation)是一种基于data randomness的uniform的融合方式。
bootstrapping指从给定训练集中有放回的均匀抽样。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/bootstarpping_aggregation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Uniform blending有一个好的特性，它可以降低模型的variance。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/uniform-blending-reduces-variance.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;random-forest-1&quot;&gt;Random forest&lt;/h3&gt;

&lt;p&gt;Bagging方法通过voting可以减小variance，而decision tree具有良好的bias表现，但有large variance(特别是fully-grown DTree)。所以一个直观的想法，能否将Bagging和Decision Tree这两者融合在一起，这样得到的新模型则具备了相对良好的bias和variance表现，这就是Random forest。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Bagging-and-Decision-Tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;random forest (RF) = bagging + fully-grown C&amp;amp;RT decision tree&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/random_forest_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bagging是data randomness，而为了增强diversity(即得到更多不同的g_t)，还可以对建立decision tree的features做抽样，即random subspace。该思想也可以套用在其他模型上(譬如svm，lr)。&lt;/p&gt;

&lt;p&gt;在build decision tree时，每一次做branch的时候，都可以做一次random re-sample feature，这样可以让g_t 更不一样。&lt;/p&gt;

&lt;p&gt;除此外，还可以利用random combination，也就是在branching时，不仅仅只是随机选择一个feature做切分，还可以random多个feature，将feature做linear combination后，再来做切分。random combination理论上就是一个perceptron过程。&lt;/p&gt;

&lt;p&gt;所以，Random forest是bagging + random-subspace &amp;amp; random-combination CART，可以看到randomness思想在random forest里无处不在。&lt;/p&gt;

&lt;p&gt;回顾一下bagging的过程，每次随机抽样一些数据，这样下去，总会有一些样本是一直未被抽中的，这些样本我们称之为out-of-bag examples，它们可以被当作validation set来使用。所以，random forest的另一个重要特性是：相比于通常的validation过程，RF可以做self-validation，也就是在训练的过程中，把model选择顺便也做了。&lt;/p&gt;

&lt;h2 id=&quot;adaboost&quot;&gt;AdaBoost&lt;/h2&gt;

&lt;h3 id=&quot;boosting&quot;&gt;Boosting&lt;/h3&gt;

&lt;p&gt;Boosting的思想相当的简单，对一份数据，建立M个模型（比如分类），一般这种模型比较简单，称为弱分类器(weak learner)。每次分类都将上一次分错的数据权重提高一点再进行分类，这样最终得到的分类器在测试数据与训练数据上都可以得到比较好的成绩。Boosting也就是开篇所述的linear blending模型。&lt;/p&gt;

&lt;p&gt;boosting可以用下面公式来表示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/boosting_formula1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中alpha是权重，y_m是弱分类器，整体就是一个linear模型。&lt;/p&gt;

&lt;p&gt;从Function Space里的Numerical Optimization角度看Boosting。boosting也叫forward stagewise additive modeling，因为在迭代的过程中，我们不能再回退去修改以前的参数，一切只能向前看了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Function-Space-optimizaition1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Function-Space-optimizaition2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Function-Space-optimizaition3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不同的损失函数和极小化损失函数方法决定了boosting的最终效果，先说几个常见的boosting：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/boosting_category.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图出自 Machine Learning A Probabilistic Perspective Table 16.1(P556)。不过其中注释的algorithm和个人理解有些不一致，Absolute error应该是叫Least Absolute Deviation (LAD) Regression。Gradient boosting的常见示例是squared loss。&lt;/p&gt;

&lt;p&gt;Boosting方法共性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Train one base learner at a time&lt;/li&gt;
  &lt;li&gt;Focus it on the mistakes of its predecessors&lt;/li&gt;
  &lt;li&gt;Weight it based on how ‘useful’ it is in the ensemble (not on its training error)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;更多请参考：&lt;a href=&quot;http://www.cs.man.ac.uk/~stapenr5/boosting.pdf&quot;&gt;Introduction to Boosting&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;adaboost-1&quot;&gt;AdaBoost&lt;/h3&gt;
&lt;p&gt;AdaBoost(Adaptive Boosting)由Yoav Freund和Robert Schapire提出。AdaBoost方法的自适应在于：前一个分类器分错的样本会被用来训练下一个分类器。AdaBoost方法对于噪声数据和异常数据很敏感。但在一些问题中，AdaBoost方法相对于大多数其它学习算法而言，不会很容易出现过拟合现象。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/adaboost_algorithm1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AdaBoost方法是一种迭代算法，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率。每一个训练样本都被赋予一个权重，表明它被某个分类器选入训练集的概率。如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它被选中的概率就被降低；相反，如果某个样本点没有被准确地分类，那么它的权重就得到提高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/adaboost_pseudo_code.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过这样的方式，AdaBoost方法能“聚焦于”那些较难分（更富信息）的样本上。在具体实现上，最初令每个样本的权重都相等，对于第k次迭代操作，我们就根据这些权重来选取样本点，进而训练分类器g_k。然后就根据这个分类器，来提高被它分错的的样本的权重，并降低被正确分类的样本权重。然后，权重更新过的样本集被用于训练下一个分类器g_k。整个训练过程如此迭代地进行下去。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Theoretical-Guarantee-of-AdaBoost.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Boosting view of AdaBoost&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;AdaBoost方法中使用的分类器可能很弱（比如出现很大错误率），但只要它的分类效果比随机好一点（比如两类问题分类错误率略小于0.5），就能够改善最终得到的模型。而错误率高于随机分类器的弱分类器也是有用的，因为在最终得到的多个分类器的线性组合中，可以给它们赋予负系数，同样也能提升分类效果。&lt;/p&gt;

&lt;h3 id=&quot;adaboost-dtree&quot;&gt;AdaBoost-DTree&lt;/h3&gt;
&lt;p&gt;将AdaBoost和decision tree融合起来，就是AdaBoost-DTree，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/adaboost_decision_tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在AdaBoost模型中，需要给予不同样本不同的权重。如果模型是svm或lr的话，很容易把weight加到每个instance上，只需要在计算loss function的时候，乘上相应的weight系数即可。&lt;/p&gt;

&lt;p&gt;但在AdaBoost-DTree模型中，对于DTree，不方便赋予weight给不同样本。这时可以利用bootstrap的思想。&lt;/p&gt;

&lt;p&gt;Bootstrap，它在每一步迭代时不改变模型本身，而是从N个instance训练集中按随机抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮，由于数据集变了迭代模型训练结果也不一样。&lt;/p&gt;

&lt;p&gt;在AdaBoost-DTree模型抽样时，并不是Uniform抽样，而是根据一定概率来抽样。如果一个instance在前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。&lt;/p&gt;

&lt;h3 id=&quot;optimizationadaboost&quot;&gt;Optimization视角看AdaBoost&lt;/h3&gt;

&lt;p&gt;从前述AdaBoost的训练过程，可以得到其训练目标为：让正确instance的weight越来越小，正确的instance个数越多越好。&lt;/p&gt;

&lt;p&gt;那么其最终目标为：第T次训练时，所有instance的weight之和最小。写出其Error function为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/AdaBoost-Error-Function1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/AdaBoost-Error-Function2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/AdaBoost-Error-Function3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面的优化目标，可以得到AdaBoost的loss function是exponential loss。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/adaboost_lost_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么选择Exponential Loss？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Loss is higher when a prediction is wrong.&lt;/li&gt;
  &lt;li&gt;Loss is steeper when a prediction is wrong.&lt;/li&gt;
  &lt;li&gt;Precise reasons later&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;求解AdaBoost的优化目标，得到下一个h(x_n)即为A(base algorithm)，h上的权重即为a_t。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Gradient-Descent-on-AdaBoost.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具体的推导过程参考”机器学习技法”课程，这里不赘述了。总结下来，AdaBoost：steepest decent with approximate functional gradient。&lt;/p&gt;

&lt;h2 id=&quot;gbdt&quot;&gt;GBDT&lt;/h2&gt;

&lt;h3 id=&quot;gradientboost&quot;&gt;GradientBoost&lt;/h3&gt;

&lt;p&gt;Gradient Boosting是一种Boosting的方法。
与传统的Boost的区别是，每一次的计算是为了减少上一次的残差(residual)，而为了消除残差，我们可以在残差减少的梯度(Gradient)方向上建立一个新的模型。所以说，在Gradient Boost中，每个新的模型的建立是为了使得之前模型的残差往梯度方向减少，与传统Boost对正确、错误的样本进行加权有着很大的区别。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/gradient_boost1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GradientBoost: allows extension to different err for regression/soft classification/etc。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/gradientBoost_for_regression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/residuals_for_gbdt.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考&lt;a href=&quot;http://www.cnblogs.com/LeftNotEasy/archive/2011/01/02/machine-learning-boosting-and-gradient-boosting.html&quot;&gt;模型组合(Model Combining)之Boosting与Gradient Boosting&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;gradient-boost-decision-tree&quot;&gt;Gradient boost decision tree&lt;/h3&gt;
&lt;p&gt;目前GBDT有两个不同的描述版本。&lt;a href=&quot;http://hi.baidu.com/hehehehello/item/96cc42e45c16e7265a2d64ee&quot;&gt;残差版本&lt;/a&gt;把GBDT当做一个残差迭代树，认为每一棵回归树都在学习前N-1棵树的残差。&lt;a href=&quot;http://blog.csdn.net/dark_scope/article/details/24863289&quot;&gt;Gradient版本&lt;/a&gt;把GBDT说成一个梯度迭代树，使用梯度下降法求解，认为每一棵回归树在学习前N-1棵树的梯度下降值。这两种描述版本我认为是一致的，因为损失函数的梯度下降方向，就是残差方向。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/gbdt_algorithm1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;意为gradient boost decision tree。又叫MART（Multiple Additive Regression Tree)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;kimmyzhang的ppt: Gradient Boosted Decision Tree&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gradient Boosting Machine：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/gradient_boosting_machine.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GB+DT+squared error loss：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/gbdt_squaredloss.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考：&lt;a href=&quot;http://www.360doc.com/content/14/1205/20/11230013_430680346.shtml&quot;&gt;GBDT迭代决策树&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;
&lt;p&gt;GBDT的常见regularization方法有：控制树的个数(即early stop)，对每一棵树控制其深度、叶子节点个数。&lt;/p&gt;

&lt;p&gt;除此外，还可以在每次训练树时，对data和feature做subsampling。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/sampling_shrinkage.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另一个常见的正则方法是Shrinkage。Shrinkage（缩减）的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/shrinkage_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;gbdt-1&quot;&gt;GBDT应用&lt;/h3&gt;
&lt;p&gt;最近，gbdt模型在搜索排序里得到大量应用。除此外，GBDT还可以用来做特征选择和特征组合。&lt;/p&gt;

&lt;p&gt;比较有代表性的是facebook的文章
&lt;a href=&quot;http://quinonero.net/Publications/predicting-clicks-facebook.pdf&quot;&gt;Practical Lessons from Predicting Clicks on Ads at Facebook&lt;/a&gt;提到的方法，它利用GBDT+LR做CTR预估，取得不错的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/facebook_gdbt_lr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果想通过代码学习GBDT，可以参考code：&lt;a href=&quot;https://github.com/zzbased/kaggle-2014-criteo&quot;&gt;kaggle-2014-criteo my notes&lt;/a&gt;，&lt;a href=&quot;https://github.com/dmlc/xgboost&quot;&gt;陈天奇的xgboost&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;总结&lt;/h2&gt;

&lt;h3 id=&quot;aggregation-1&quot;&gt;Aggregation方法总结&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Blending Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;blending: aggregate after getting diverse g_t&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/blending_models.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aggregation-Learning Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;learning: aggregate as well as getting diverse g_t&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Aggregation-Learningmodels.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aggregation of Aggregation Models&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Aggregation-of-Aggregation-Models.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;为什么Aggregation方法是有效的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;可以从两方面来看，其一通过Aggregation可以生成复杂的hypotheses，相当于做了feature transform；其二，生成的G(x)更加moderate，例如下图中PLA的uniform mix就是large-margin，相当于做了regularization。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/aggregation_works.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;boosting-1&quot;&gt;Boosting方法比较&lt;/h3&gt;

&lt;p&gt;关于boosting方法的比较，上文中mlapp的图已经表达得比较明确了。这里再在公式上做一下细化。&lt;/p&gt;

&lt;p&gt;Square and Absolute Error：
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Square-and-Absolute-Error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Logistic Loss and LogitBoost：
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Logistic-Loss-and-LogitBoost.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Exponential Loss and Adaboost：
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/aggregation/Exponential-Loss-and-Adaboost.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面把一些常见方法的特点再加强阐述下。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Adaboost：一种boost方法，它按分类对错，分配不同的weight，计算cost function时使用这些weight，从而让“错分的样本权重越来越大，使它们更被重视”。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GBDT的核心在于：每一棵树学的是之前所有树的结论和残差。每一步的残差计算其实变相地增大了分错instance的权重，而已经分对的instance则都趋向于0。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bootstrap，它在每一步迭代时不改变模型本身，也不计算残差，而是从N个instance训练集中按一定概率重新抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮，由于数据集变了迭代模型训练结果也不一样。&lt;/p&gt;

    &lt;p&gt;如果一个instance被前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。这里是决策树给予不同样本不同权重的方法。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;一篇不错的综述性文章：&lt;a href=&quot;http://www.52cs.org/?p=383&quot;&gt;集成学习：机器学习刀光剑影 之 屠龙刀&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bagging和boosting也是当今两大杀器RF（Random Forests）和GBDT（Gradient Boosting Decision Tree）之所以成功的主要秘诀。&lt;/li&gt;
  &lt;li&gt;Bagging主要减小了variance，而Boosting主要减小了bias，而这种差异直接推动结合Bagging和Boosting的MultiBoosting的诞生。参考:Geoffrey I. Webb (2000). MultiBoosting: A Technique for Combining Boosting and Wagging. Machine Learning. Vol.40(No.2)&lt;/li&gt;
  &lt;li&gt;LMT(Logistic Model Tree ) 应运而生，它把LR和DT嫁接在一起，实现了两者的优势互补。对比GBDT和DT会发现GBDT较DT有两点好处：1）GBDT本身是集成学习的一种算法，效果可能较DT好；2）GBDT中的DT一般是Regression Tree，所以预测出来的绝对值本身就有比较意义，而LR能很好利用这个值。这是个非常大的优势，尤其是用到广告竞价排序的场景上。&lt;/li&gt;
  &lt;li&gt;关于Facebook的GBDT+LR方法，它出发点简单直接，效果也好。但这个朴素的做法之后，有很多可以从多个角度来分析的亮点：可以是简单的stacking，也可以认为LR实际上对GBDT的所有树做了选择集成，还可以GBDT学习了基，甚至可以认为最后的LR实际对树做了稀疏求解，做了平滑。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;更多学习资料&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://suanfazu.com/t/gbdt-die-dai-jue-ce-shu-ru-men-jiao-cheng/135&quot;&gt;Gbdt迭代决策树入门教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.schonlau.net/publication/05stata_boosting.pdf&quot;&gt;Boosting Decision Tree入门教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://research.microsoft.com/pubs/132652/MSR-TR-2010-82.pdf&quot;&gt;LambdaMART用于搜索排序入门教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://insidebigdata.com/2014/12/18/ask-data-scientist-ensemble-methods/&quot;&gt;文章 Ask a Data Scientist: Ensemble Methods&lt;/a&gt; “Ask a Data Scientist.”系列文章之Ensemble Methods，通俗程度可以和昨天介绍的Quora随机森林解释相媲美，但更为详尽，对常用Ensemble框架及其特点也进行了介绍，很好。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cvchina.net/post/107.html&quot;&gt;决策树模型组合之随机森林与GBDT&lt;/a&gt;
  &lt;a href=&quot;http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html&quot;&gt;机器学习中的算法(1)-决策树模型组合之随机森林与GBDT link2&lt;/a&gt;
  模型组合与决策树相关的算法比较多，这些算法最终的结果是生成N棵树，这样可以大大的减少单决策树带来的毛病，有点类似于三个臭皮匠等于一个诸葛亮的做法，虽然这几百棵决策树中的每一棵都很简单，但是他们组合起来确是很强大。&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://statweb.stanford.edu/~jhf/ftp/trebst.pdf&quot;&gt;经典文章 Greedy function approximation : A Gradient Boosting Machine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/tqchen/xgboost&quot;&gt;xgboost - eXtreme Gradient Boosting (GBDT or GBRT) Library, also support distributed learning&lt;/a&gt;
  并行实现推荐 @陈天奇怪 的xgboost，实际例子见@phunter_lau 最近的文章 http://t.cn/RhKAWac&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://machinelearning.wustl.edu/pmwiki.php/Main/Pgbrt&quot;&gt;pGBRT: Parallel Gradient Boosted Regression Trees&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://bigdata.memect.com/?tag=GBDT&quot;&gt;更多GBDT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.hankcs.com/ml/decision-tree.html&quot;&gt;决策树 用Python实现了决策树的ID3生成算法和C4.5生成算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://t.cn/RZBT6Ap&quot;&gt;论文 Understanding Random Forests: From Theory to Practice&lt;/a&gt;
Louppe, Gilles的博士论文，全面了解随机森林的好材料，推荐！pdf: http://t.cn/RZBTobH 云:http://t.cn/RZBTobT&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.datadive.net/interpreting-random-forests/&quot;&gt;Interpreting random forests&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://toutiao.com/a4055188882/&quot;&gt;计算机视觉：随机森林算法在人体识别中的应用&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;J. Friedman(1999). Greedy Function Approximation: A Gradient Boosting Machine.&lt;/li&gt;
  &lt;li&gt;J. Friedman(1999). Stochastic Gradient Boosting.&lt;/li&gt;
  &lt;li&gt;J. Friedman, T. Hastie, R. Tibshirani(2000). Additive Logistic Regression - A Statistical View of Boosting.&lt;/li&gt;
  &lt;li&gt;T. Hastie, R. Tibshirani, J. Friedman(2008). Chapter 10 of The Elements of Statistical Learning(2e).&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 03 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/04/03/Aggregation%E6%A8%A1%E5%9E%8B.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/04/03/Aggregation%E6%A8%A1%E5%9E%8B.html</guid>
        
        
      </item>
    
      <item>
        <title>Python零碎</title>
        <description>&lt;h1 id=&quot;python&quot;&gt;Python零碎&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/vivilisa/archive/2009/03/19/1417083.html&quot;&gt;Enumerate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;enumerate会将数组或列表组成一个索引序列。使我们再获取索引和索引内容的时候更加方便如下：
	for index，text in enumerate(list)):
	   print index ,text&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/3815860/python-how-to-exit-main-function&quot;&gt;Python how to exit main function&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/65702708/archive/2010/09/14/1826362.html&quot;&gt;Python sorted函数&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/emaste_r/article/details/8447192&quot;&gt;Python各种类型转换-int,str,char,float,ord,hex,oct等&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int(x [,base ])         将x转换为一个整数
long(x [,base ])        将x转换为一个长整数
float(x )               将x转换到一个浮点数
complex(real [,imag ])  创建一个复数
str(x )                 将对象 x 转换为字符串
repr(x )                将对象 x 转换为表达式字符串
eval(str )              用来计算在字符串中的有效Python表达式,并返回一个对象
tuple(s )               将序列 s 转换为一个元组
list(s )                将序列 s 转换为一个列表
chr(x )                 将一个整数转换为一个字符
unichr(x )              将一个整数转换为Unicode字符
ord(x )                 将一个字符转换为它的整数值
hex(x )                 将一个整数转换为一个十六进制字符串
oct(x )                 将一个整数转换为一个八进制字符串
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/379906/parse-string-to-float-or-int&quot;&gt;Parse Float String to Int&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; a = &quot;545.2222&quot;
&amp;gt;&amp;gt;&amp;gt; float(a)
545.22220000000004
&amp;gt;&amp;gt;&amp;gt; int(float(a))
545
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Wed, 01 Apr 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/04/01/python%E9%9B%B6%E7%A2%8E.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/04/01/python%E9%9B%B6%E7%A2%8E.html</guid>
        
        
      </item>
    
      <item>
        <title>Expectation-Maximization algorithm</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;em&quot;&gt;EM算法随笔&lt;/h1&gt;

&lt;h2 id=&quot;em-overview&quot;&gt;EM overview&lt;/h2&gt;

&lt;p&gt;The EM algorithm belongs to a broader class of alternating minimization algorithms.&lt;/p&gt;

&lt;p&gt;EM is one such hill-climbing algorithm that converges to a local maximum of the likelihood surface.&lt;/p&gt;

&lt;p&gt;As the name suggests, the EM algorithm alternates between an expectation and a maximization step. The “E step” finds a lower bound that is equal to the log-likelihood function at the current parameter estimate θ_k. The “M step” generates the next estimate θ_k+1 as the parameter that maximizes this greatest lower bound.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/em_image1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x是隐变量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/em_q_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/em_formula2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Zhai chengxiang老师的经典EM note：&lt;a href=&quot;http://www.cs.ust.hk/~qyang/Teaching/537/PPT/em-note.pdf&quot;&gt;A Note on the Expectation-Maximization (EM) Algorithm&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shane M. Haas的&lt;a href=&quot;http://www.mit.edu/~6.454/www_fall_2002/shaas/summary.pdf&quot;&gt;The Expectation-Maximization and Alternating Minimization Algorithms&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;emplsa&quot;&gt;EM于PLSA&lt;/h2&gt;

&lt;p&gt;PLSA的图模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_graph_model.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PLSA的生成过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_procedure.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(di,wj)的联合分布为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_formula1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PLSA的最大似然函数为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_likelihood.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意上式中，第一项的完整形式为：
\(\sum&lt;em&gt;{i=1}^N{\sum&lt;/em&gt;{j=1}^M{n(d_i,w_j) log(p(d_i))}}\)。&lt;/p&gt;

&lt;p&gt;对于这样的包含”隐含变量”或者”缺失数据”的概率模型参数估计问题，我们采用EM算法。这两个概念是互相联系的，当我们的模型中有”隐含变量”时，我们会认为原始数据是”不完全的数据”，因为隐含变量的值无法观察到；反过来，当我们的数据incomplete时，我们可以通过增加隐含变量来对”缺失数据”建模。&lt;/p&gt;

&lt;p&gt;EM算法的步骤是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;E步骤：Given当前估计的参数条件下，求隐含变量的后验概率。
an expectation (E) step where posterior probabilities are computed for the latent variables, based on the current estimates of the parameters。&lt;/li&gt;
  &lt;li&gt;M步骤：最大化Complete data对数似然函数的期望，此时我们使用E步骤里计算的隐含变量的后验概率，得到新的参数值。
a maximization (M) step, where parameters are updated based on the so-called expected complete data log-likelihood which depends on the posterior probabilities computed in the E-step。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两步迭代进行直到收敛。&lt;/p&gt;

&lt;p&gt;这里是通过最大化”complete data”似然函数的期望，来最大化”incomplete data”的似然函数，以便得到求似然函数最大值更为简单的计算途径。&lt;/p&gt;

&lt;p&gt;PLSA的E-Step：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_e_step.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;PLSA的M-step，M-step的推导过程请参考下面的文献。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/em/plsa_m_step.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cs.bham.ac.uk/~pxt/IDA/plsa.pdf&quot;&gt;Unsupervised Learning by Probabilistic Latent Semantic Analysis&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/yangliuy/article/details/8330640&quot;&gt;概率语言模型及其变形系列(1)-PLSA及EM算法&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;emgmm&quot;&gt;EM于GMM&lt;/h2&gt;

&lt;p&gt;PRML第9章。&lt;/p&gt;

&lt;h2 id=&quot;emhmm&quot;&gt;EM于HMM&lt;/h2&gt;

</description>
        <pubDate>Fri, 27 Mar 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/03/27/EM%E7%AE%97%E6%B3%95%E9%9A%8F%E7%AC%94.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/03/27/EM%E7%AE%97%E6%B3%95%E9%9A%8F%E7%AC%94.html</guid>
        
        
      </item>
    
      <item>
        <title>机器学习技法学习笔记</title>
        <description>
&lt;hr /&gt;
&lt;p&gt;layout: post
title: “机器学习技法学习笔记”
—&lt;/p&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;section&quot;&gt;机器学习技巧 学习笔记&lt;/h1&gt;

&lt;p&gt;有用链接：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/course/ntumlone&quot;&gt;机器学习基石&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://class.coursera.org/ntumltwo-001/lecture&quot;&gt;机器学习技法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://beader.me/mlnotebook/&quot;&gt;beader.me笔记&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.douban.com/doulist/3440234/&quot;&gt;听课笔记douban&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mooc.guokr.com/course/610/機器學習基石--Machine-Learning-Foundations-/&quot;&gt;mooc学院&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;linear-support-vector-machines&quot;&gt;第1讲 Linear Support Vector Machines&lt;/h2&gt;

&lt;p&gt;我们的目标是：最大间隔&lt;/p&gt;

&lt;p&gt;求一个点x距离一个平面的距离：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;点x到平面上的点x’的向量 x-x’，在平面的法向量上的投影：w*(x-x’)/&lt;/td&gt;
      &lt;td&gt;w&lt;/td&gt;
      &lt;td&gt;，即&lt;/td&gt;
      &lt;td&gt;w^T*x+b&lt;/td&gt;
      &lt;td&gt;/&lt;/td&gt;
      &lt;td&gt;w&lt;/td&gt;
      &lt;td&gt;。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;最大化这个距离，可以假设 min{y*(wx+b)}=1。那么目标变为：&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;max 1/&lt;/td&gt;
      &lt;td&gt;w&lt;/td&gt;
      &lt;td&gt;条件是： min{y*(wx+b)}=1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;进一步推导，得到最终优化的目标：&lt;/p&gt;

&lt;p&gt;min 1/2 w*w^T  subject to y(wx+b)&amp;gt;=1&lt;/p&gt;

&lt;p&gt;这就是支持向量机的优化目标，它的损失函数，等同于： max{0, 1-ywx}&lt;/p&gt;

&lt;p&gt;注意：函数间隔与几何间隔。&lt;/p&gt;

&lt;p&gt;可以将这个优化目标转化到 &lt;a href=&quot;http://cn.mathworks.com/discovery/quadratic-programming.html&quot;&gt;二次规划 quadratic programming&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/quadratic_programming.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;large-margin algorithm的VC维分析。因为large margin的限制，相比于较于PLA，svm的dichotomies会更少。所以从VC维看，相比于PLA，其泛化能力更强。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/vc_dimension_of_large_margin_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;large-margin hyperplanes：参数最少，所以boundary最简单。
一般的hyperplanes：参数适中，边界简单。
一般的hyperplanes+feature转换(非线性的)：参数较多，边界复杂。
large-margin hyperplanes+feature transform：则可以得到适中的参数个数，复杂的边界。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Benefits-of-Large-Margin-Hyperplanes.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;扩展阅读&lt;/strong&gt;
&lt;a href=&quot;http://blog.csdn.net/v_july_v/article/details/7624837&quot;&gt;支持向量机通俗导论（理解SVM的三层境界）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter1_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter1_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;dual-support-vector-machine&quot;&gt;第2讲 Dual support vector machine&lt;/h2&gt;

&lt;p&gt;讨论： Support Vector Classification，Logistic Regression，Support Vector Regression的区别：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/L2-regularized-L1-and-L2-loss-Support-Vector-Classification.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/L2-regularized-Logistic-Regression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/L1-regularized-L2-loss-Support-Vector-Classification.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/L1-regularized-Logistic-Regression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/L2-regularized-L1-and-L2-loss-Support-Vector-Regression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;复习一下第1讲，直接求解SVM的original问题，利用QP方法，需要求解 d+1个变量(d指代feature转换后的维度)，N个约束条件。如果我们采用一个非线性变换，维度特别高，就不太可解了，所以我们想SVM without d。所以有 ‘Equivalent’ SVM: based on some dual problem of Original SVM。&lt;/p&gt;

&lt;p&gt;这时就要用到lagrange multipliers。这里看下正则化，为什么正则化的表达式是这样的，这是通过lagrange multipliers。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Lagrange-Multipliers-regularization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是SVM的对偶问题推导过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Lagrange-Function1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/lagrange-dual-problem2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里要提一下KKT条件：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/kkt_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/kkt_12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;经过一通推导，我们得到了svm的对偶问题：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Dual-Formulation-of-svm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个对偶问题，就可以用QP来求解了。&lt;/p&gt;

&lt;p&gt;求得a后，primal问题的w和b，可以通过下面式子求得：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/w_b_optim.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后说一个解释：当a_n大于0时，此时该点正好处于边界上，这也就是所谓的支撑向量。&lt;/p&gt;

&lt;p&gt;有趣之处在于，对于新点x的预测，只需要计算它与训练数据点的内积即可（表示向量内积），这一点至关重要，是之后使用 Kernel 进行非线性推广的基本前提。此外，所谓 Supporting Vector 也在这里显示出来——事实上，所有非Supporting Vector 所对应的系数都是等于零的，因此对于新点的内积计算实际上只要针对少量的“支持向量”而不是所有的训练数据即可。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter2_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter2_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter2_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter2_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;第3讲&lt;/h2&gt;
&lt;p&gt;为什么要把SVM转换到对偶问题，原因有这样几个：1.对偶问题的变量为N个，有时候N远远小于d。2.解释了support vector。 3.比较直观的引入了核函数。&lt;/p&gt;

&lt;p&gt;在线性不可分的情况下，支持向量机首先在低维空间中完成计算，然后通过核函数将输入空间映射到高维特征空间，最终在高维特征空间中构造出最优分离超平面，从而把平面上本身不好分的非线性数据分开。&lt;/p&gt;

&lt;p&gt;建立非线性学习器分为两步：
首先使用一个非线性映射将数据变换到一个特征空间F，
然后在特征空间使用线性学习器分类。&lt;/p&gt;

&lt;p&gt;核函数的优势在于：
一个是映射到高维空间中，然后再根据内积的公式进行计算；
而另一个则直接在原来的低维空间中进行计算，而不需要显式地写出映射后的结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Kernel-SVM-with-QP.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;多项式核：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Poly-2-Kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SVM + Polynomial Kernel: Polynomial SVM&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Poly-Kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;高斯核：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/gaussian_kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看一下高斯核参数改变带来的变化：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/gaussian_kernel2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面对比一下常用的几种核函数：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/compare_linear_kernel.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/compare_poly_kernel.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/compare_gaussian_kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，除了上面三种常用的核函数外，还可以自己构造一些核，只需要这些核满足mercer’s condition。不过需要说明的，很难。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/valid_kernel_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter3_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter3_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;第4讲&lt;/h2&gt;

&lt;p&gt;使用松弛变量处理 outliers 方法，本讲的内容。&lt;/p&gt;

&lt;h2 id=&quot;blending-and-bagging&quot;&gt;第6讲  Blending and Bagging&lt;/h2&gt;

&lt;p&gt;Aggregation的方法包括：select, mix uniformly, mix non-uniformly, combine;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/aggregation_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为什么Aggregation方法是有效的？可以从两方面来看，其一通过Aggregation可以生成复杂的hypotheses，相当于做了feature transform；其二，生成的G(x)更加moderate，例如下图中PLA的uniform mix就是large-margin，相当于做了regularization。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/aggregation_works.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;uniform blending&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果是classification，则有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/uniform_blending_for_classification.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果是regression，则有：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/uniform_blending_for_regression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图还可以看出：任意g的Eout平均大于等于G的Eout。&lt;/p&gt;

&lt;p&gt;从上图的公式还可以得出，expected performance of A = expected deviation to consensus +performance of consensus。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/uniform_blending_reduce_variance.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Linear Blending&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;linear blending就像two-level learning。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear_blending.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;like selection, blending practically done with (Eval instead of Ein) + (gt− from minimum Etrain)&lt;/p&gt;

&lt;p&gt;Any blending也叫Stacking。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/any_blending.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;bagging&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;aggregation里最重要的一个点就是：diversity。diversity的方法有很多种。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/diversity_important.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面介绍一种通过data randomness的方法，也叫bootstrapping，即bagging。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/bootstarpping1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter7_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;adaptive-boosting&quot;&gt;第8讲 Adaptive Boosting&lt;/h2&gt;

&lt;p&gt;课程的最开始有一个分辨苹果的例子。以后AdaBoost的时候可以借鉴那个例子。其基本思路是：给予上次分错的样本更高的权重。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/re_weighting_bootstrapping.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;给每个example不同的weight，类似于给予不同的class的样本不同的weight。回忆一下，有时候我们false reject尽可能低，那对于这一类，我们在error measure给予更高的权重。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/re_weighting_bootstrapping2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/false-accept-and-false-reject.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具体怎么更新下一次训练的样本权重呢，参考下面的图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/scaling_factor.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了样本权重更新公式后，则有一个Preliminary算法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/adaboost_preliminary.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;得到这么多的g后，怎么得到G，也就是aggregation的方法，我们希望在计算g的时候把aggregation的权重也得到。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/adaboost1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么完整算法为：
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/adaboost2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是一些理论：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Theoretical-Guarantee-of-AdaBoost.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Decision Stump&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Decision-Stump.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AdaBoost与Decision Stump的结合 – &amp;gt; AdaBoost-Stump:
efficient feature selection and aggregation&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter8_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;decision-tree&quot;&gt;第9讲 Decision Tree&lt;/h2&gt;

&lt;p&gt;decision tree的位置，模仿人脑决策过程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/decision-tree1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;decision tree缺点：(1)启发式的规则(前人的巧思)，缺乏理论基础；(2)启发式规则很多，需要selection；(3)没有代表性的算法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Disclaimers-about-Decision-Tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个基本的decision tree算法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/basic-decision-tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CART: classification and regression tree。
有两个简单的选择：binary tree；叶子节点是常数。&lt;/p&gt;

&lt;p&gt;怎么选择branching，切完后两个子树的纯度最高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Purifying-in-CART.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;怎么考量”不纯度”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Impurity-Functions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最终CART算法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/cart_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于CART算法的演算过程，具体请参考 &lt;a href=&quot;http://mydisk.com/yzlv/webpage/datamining/xiti.html&quot;&gt;决策树算法的计算过程演示&lt;/a&gt;，&lt;a href=&quot;http://en.wikipedia.org/wiki/Decision_tree_learning&quot;&gt;Decision tree learning&lt;/a&gt;，&lt;a href=&quot;http://www.academia.edu/7032069/An_example_of_calculating_gini_gain_in_CART&quot;&gt;An example of calculating gini gain in CART&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;几种决策树算法的区别：&lt;/p&gt;

&lt;p&gt;C4.5算法是在ID3算法的基础上采用信息增益率的方法选择测试属性。 ID3算法和C4.5算法虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但其生成的决策树分支较大，规模较大。为了简化决策树的规模，提高生成决策树的效率，又出现了根据GINI系数来选择测试属性的决策树算法CART。
CART算法采用一种二分递归分割的技术，与基于信息熵的算法不同，CART算法对每次样本集的划分计算GINI系数，GINI系数，GINI系数越小则划分越合理。CART算法总是将当前样本集分割为两个子样本集，使得生成的决策树的每个非叶结点都只有两个分枝。因此CART算法生成的决策树是结构简洁的二叉树。&lt;/p&gt;

&lt;p&gt;Regularization&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Regularization-by-Pruning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当有categorical features时，CART也可以灵活处理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Branching-on-Categorical-Features.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果有缺失特征的话，怎么办？可以利用surrogate feature。&lt;/p&gt;

&lt;p&gt;看一个CART的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/cart_example.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter9_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;random-forest&quot;&gt;第10讲 random forest&lt;/h2&gt;
&lt;p&gt;Bagging and Decision Tree，将这两者合在一起，就是Random forest。&lt;/p&gt;

&lt;p&gt;random forest (RF) = bagging + fully-grown C&amp;amp;RT decision tree&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Bagging-and-Decision-Tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;三个优点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;highly parallel/efficient to learn&lt;/li&gt;
  &lt;li&gt;inherit pros of C&amp;amp;RT&lt;/li&gt;
  &lt;li&gt;eliminate cons of fully-grown tree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为是random forest，除了在bootstrapping时利用data randomness，还可以randomly sample d’ feature from x。即original RF re-sample new subspace for each b(x) in C&amp;amp;RT。&lt;/p&gt;

&lt;p&gt;那么更进一步了，RF = bagging + random-subspace C&amp;amp;RT&lt;/p&gt;

&lt;p&gt;random-combination的意思是：随机抽样一些features后，line combination，作为一个新的feature切分点。那么original RF consider d′ random low-dimensional projections for each b(x) in C&amp;amp;RT。&lt;/p&gt;

&lt;p&gt;所以，再进一步：RF = bagging + random-combination C&amp;amp;RT&lt;/p&gt;

&lt;p&gt;从上面可以看出，randomness是随处不在的。&lt;/p&gt;

&lt;p&gt;回顾一下bagging的过程，每次随机抽样一些数据，这样下去，总会有一些样本是一直未被抽中的。未被抽中的概率计算为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/numbers_of_oob.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了这些out-of-bag (OOB) examples后，可以将其作为validation set来使用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/oob_vs_validation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那么，相比于原来的validation过程，RF可以做self-validation，也就是在训练的过程中，把model选择顺便也做了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/model_selection_by_oob.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接着看下Feature selection，decision tree正好是一个内建的feature selection过程。&lt;/p&gt;

&lt;p&gt;先看下利用linear model做feature importance判别，训练完的模型，weight越大，表示feature越重要。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Feature_Selection_by_Importance.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而RF可以采用permutation test来做特征选择。所谓permutation test，也就是对某一个特征，对所有样本上该维度的特征值做随机排列，然后在这个样本集上计算RF performance。用原来的performance减去这个新的performance后，就得到该特征的重要性。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/feature_selection_by_permutation_test.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是在RF上，因为OOB的存在，可以利用Eoob(G)-Eoob^p(G)。Eoob^p(G)是通过在OOB上permute某一维特征值。&lt;strong&gt;这里后续可以再深挖&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/feature_importance_by_rf.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter10_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter10_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gradient-boosted-decision-treegbdt&quot;&gt;第11讲 Gradient Boosted Decision Tree(GBDT)&lt;/h2&gt;

&lt;p&gt;random forest用一句话来总结，则是：bagging of randomized C&amp;amp;RT trees with automatic validation and feature selection。&lt;/p&gt;

&lt;p&gt;比较一下Random forest和AdaBoost Tree。
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/compare_rd_adaboost-tree.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;但是要做AdaBoost Tree的话，首先需要weighted DTree。这个在LR,SVM等模型上容易做到，但是在DT上很难。所以我们换个思路，如果我们想给某个样本加个weight，可以在sample样本的时候，增大或者减小它的概率即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Randomized-Base-Algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以AdaBoost-DTree的组成由下图所示：
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/AdaBoost-DTree1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在adaboost算法中，如果一个g的错误率为0的话，那么这个g的权重将是无限大的。而在决策树的世界里，如果是full-grown的话，在训练数据上，错误率为0是很容易办到的。&lt;/p&gt;

&lt;p&gt;那么为了避免这种过拟合的情况存在，我们需要对DT做剪枝。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/AdaBoost-DTree2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当我们extremely剪枝时，譬如限制树的高度小于等于1，那此时DT就变成了decision stump。所以有了adaboost-stump算法，它是AdaBoost-DTree的一种特例。&lt;/p&gt;

&lt;p&gt;2，3，4节 未完待续。&lt;/p&gt;

&lt;p&gt;更多具体的内容，请参考单独的文章： &lt;a href=&quot;http://zzbased.github.io/2015/04/03/Aggregation模型.html&quot;&gt;Aggregation模型&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter11_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;第12讲 神经网络&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过”Linear Aggregation of Perceptrons”，可以完成AND，OR，NOT等操作，可以完成 convex set等操作，但是不能完成XOR操作。怎么办？只能multi-layer perceptron。&lt;/p&gt;

&lt;p&gt;XOR(g1, g2) = OR(AND(−g1, g2), AND(g1, −g2))&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/perceptron_powerful_limitation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;perceptron (simple)
=⇒ aggregation of perceptrons (powerful)
=⇒ multi-layer perceptrons (more powerful)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter12_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Neural Network Hypothesis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;output：any linear model can be used；
transformation function of score (signal) s：不用linear，因为多层线性=&amp;gt;whole network linear。也不用阶梯函数(0-1)，因为它不可微。通常的选择有tanh(x)，sigmoid(s)。&lt;/p&gt;

&lt;p&gt;tanh(x) = [exp(s)-exp(-s)] / [exp(s)+exp(-s)] = 2sigmoid(2x)-1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter12_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Backpropagation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Backpropagation_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Backpropagation_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter12_question3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当multiple hidden layers，一般都是non-convex。对于最优化来说，不容易求得全局最优解。GD/SGD可能只能求出局部最优解。&lt;/p&gt;

&lt;p&gt;对Wij做不同的初始化，可能有不同的局部最优解。所以对初始化值比较敏感。&lt;/p&gt;

&lt;p&gt;有效的建议是：不要初始化太大的weights，因为large weight，加上tanh后，将saturate。如果做梯度下降的话，那段区域里有small gradient。所以建议要try some random&amp;amp;small ones。&lt;/p&gt;

&lt;p&gt;神经网络的dVC=O(VD)，V表示神经元的个数，D表示weight的个数，也就是edge的数目。&lt;/p&gt;

&lt;p&gt;VC维太大，容易overfit。可以加一个L2 regularizer。但是加L2后，带来的只是shrink weights。我们希望可以得到sparse解，那么就可以用L1 regularizer，但L1不可微分。
所以另外一个选择是：weight-elimination（scaled L2），即large weight → median shrink; small weight → median shrink&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/weight-elimination-regularizer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Early Stopping，随着t 增长，VC维越大。所以合适的t 就够了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/BP-Early-Stopping.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter12_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;deep-learning&quot;&gt;第13讲 Deep Learning&lt;/h2&gt;

&lt;p&gt;structural decisions: key issue for applying NNet。模型结构很关键。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Challenges-and-Key-Techniques-for-Deep-Learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;hinton 2006提出的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/A-Two-Step-Deep-Learning-Framework.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Information-Preserving-Neural-Network.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Auto-encoder的作用：监督学习的话，给予做特征；无监督学习的话，用来做密度预测，也可以用来做异常点检测。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Deep-Learning-with-Autoencoders.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Regularization in Deep Learning的方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;structural decisions/constraints，譬如卷积神经网络，循环神经网络&lt;/li&gt;
  &lt;li&gt;weight decay or weight elimination regularizers&lt;/li&gt;
  &lt;li&gt;Early stopping&lt;/li&gt;
  &lt;li&gt;dropout，dropconnect等&lt;/li&gt;
  &lt;li&gt;denosing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/denosing_auto-encoder.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Linear Autoencoder Hypothesis
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear-autoencoder-hypothesis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;简单点看就是：h(x) = WW^T x&lt;/p&gt;

&lt;p&gt;复习一下特征值和特征向量。&lt;a href=&quot;http://zh.wikipedia.org/wiki/特征向量&quot;&gt;特征向量wiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/optimal_v_linear_autoencoder.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/pca-for-autoencoder.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter13_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;radial-basis-function-network&quot;&gt;第14讲 Radial Basis Function Network&lt;/h2&gt;

&lt;p&gt;以前在讲SVM时，有提到RBF kernel(gaussian kernel)，这里回顾一下。高斯核是将x空间变换到z空间的无限维。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/gaussian_svm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基于高斯核的SVM如下所示，相当于是support vector上的radial hypotheses的线性组合。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/gaussian_svm2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So，Radial Basis Function (RBF) Network: linear aggregation of radial hypotheses。&lt;/p&gt;

&lt;p&gt;将RBF network类比于neural network，output layer是一样的，都是线性组合，不一样是隐藏层(在RBF network里，是distance + gaussian)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/rbf_network.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基于RBF network来解释SVM：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/RBF-Network-Hypothesis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;此时，需要学习的参数是 u_m(是centers)，b_m(是不同rbf线性组合的系数)。&lt;/p&gt;

&lt;p&gt;kernel是Z空间的相关性度量，而RBF是X空间的相关性度量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/rbf_vs_kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以RBF network： distance similairty-to-centers as feature transform。&lt;/p&gt;

&lt;p&gt;Full RBF Network：是说将所有样本点都参与到运算里(M=N)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/full_rbf_network.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;full rbf network是一个lazy way to decide u_m。&lt;/p&gt;

&lt;p&gt;Nearest-Neighbor：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Nearest-Neighbor.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果是利用RBF network做regression呢？如下所示。但是这样做了后，Ein(g)=0，这样势必会overfit。
所以需要做正则化。正则化的思路有：(1)类似于kernel ridge regression，加正则项。(2)fewer centers，譬如support vector。constraining number of centers and voting weights。&lt;/p&gt;

&lt;p&gt;那怎样才能做到fewer centers呢？通常的方法就是：寻找prototypes。那how to extract prototypes?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Regularized-Full-RBF-Network.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里提到一种算法：k-means cluster。k-means的优化思路为：alternating minimization。说到这，EM也属于alternating minimization。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/k-Means-Algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OK，现在prototypes提取到了，接下来把基于k-means的rbf network写出来。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/RBF-Network-Using-k-Means.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是实战，先看一个k-means的例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/k-means-examples.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，k和初始化，在k-means算法里非常关键。&lt;/p&gt;

&lt;p&gt;通常随机地从样本中挑k个出来作为k个初始的聚类中心。但这不是个明智的选择。它有可能会导致图像趋于稠密聚集某些区域，因为如果训练样本本身就在某个区域分布非常密，那么我们随机去选择聚类中心的时候，就会出现就在这个数据分布密集的地方被选出了很多的聚类中心。&lt;/p&gt;

&lt;p&gt;那么怎么做k-means的初始化呢？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;多次运行数据集合，选择最小的SSE的分簇结果作为最终结果。该方法依赖于数据集合和簇数量，对分簇结果有比较大影响，所以在某些场景下效果也不是很好。&lt;/li&gt;
  &lt;li&gt;抽取数据集合样本，对样本进行Hierarchical Clustering技术，从中抽取K个Clustering作为初始中心点。该方法工作良好，知识有两点限制条件：抽样数据不能太大，因为Hierarchical Clustering比较耗时间；K值相对于抽样数据比较小才行。&lt;/li&gt;
  &lt;li&gt;kmeans++算法。&lt;a href=&quot;http://en.wikipedia.org/wiki/K-means%2B%2B&quot;&gt;kmeans++ wiki&lt;/a&gt;，&lt;a href=&quot;http://www.cnblogs.com/shelocks/archive/2012/12/20/2826787.html&quot;&gt;kmenas++中文&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;K-means++的步骤为：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;从输入的数据点集合中随机选择一个点作为第一个聚类中心&lt;/li&gt;
  &lt;li&gt;对于数据集中的每一个点x，计算它与最近聚类中心(指已选择的聚类中心)的距离D(x)&lt;/li&gt;
  &lt;li&gt;选择一个新的数据点作为新的聚类中心，选择的原则是：D(x)较大的点，被选取作为聚类中心的概率较大&lt;/li&gt;
  &lt;li&gt;重复2和3直到k个聚类中心被选出来&lt;/li&gt;
  &lt;li&gt;利用这k个初始的聚类中心来运行标准的k-means算法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;更多关于k-means初始化的方法，请参考 &lt;a href=&quot;http://www.mecs-press.org/ijisa/ijisa-v4-n1/IJISA-V4-N1-3.pdf&quot;&gt;Efficient and Fast Initialization Algorithm for K- means Clustering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;扩展阅读&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;-【发表在Science的论文：基于密度的快速无监督聚类方法】&lt;a href=&quot;http://t.cn/RAASZ4q&quot;&gt;Clustering by fast search and find of density peaks. A Rodriguez, A Laio (2014) &lt;/a&gt; 很棒，推荐给没看过的朋友，另有相关中文两篇：http://t.cn/RPoKmOi http://t.cn/RPOs6uK 供参考理解 云:http://t.cn/RAACowz&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对所有坐标点，基于相互距离，提出了两个新的属性，一是局部密度rho，即与该点距离在一定范围内的点的总数，二是到更高密度点的最短距离delta。作者提出，类簇的中心是这样的一类点：它们被很多点围绕（导致局部密度大），且与局部密度比自己大的点之间的距离也很远。
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Canopy 聚类算法的基本原则是：首先应用成本低的近似的距离计算方法高效的将数据分为多个组，这里称为一个Canopy。Canopy 之间可以有重叠的部分。然后采用严格的距离计算方式准确的计算在同一 Canopy 中的点，将他们分配与最合适的簇。Canopy 聚类算法经常用于 K 均值聚类算法的预处理，用来找合适的 k 值和簇中心。&lt;a href=&quot;http://blog.pureisle.net/archives/2045.html&quot;&gt;Clustering Algorithm/聚类算法&lt;/a&gt;，&lt;a href=&quot;http://en.wikipedia.org/wiki/Canopy_clustering_algorithm&quot;&gt;Canopy clustering algorithm&lt;/a&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/RAwxOJx&quot;&gt;文章 K-means Clustering with scikit-learn&lt;/a&gt; PyData SV 2014上Sarah Guido的报告，Python下用Scikit-Learn做K-means聚类分析的深入介绍，涉及k值选取、参数调优等问题，很实用 GitHub:http://t.cn/RAwxsFS 云(视频+讲义):http://t.cn/RAwJJkG&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/RwlDlgq&quot;&gt;文章 Divining the ‘K’ in K-means Clustering&lt;/a&gt; 用G-means算法确定K-means聚类最佳K值，G-means能很好地处理stretched out clusters(非球面伸展型类簇)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cc.gatech.edu/~isbell/tutorials/rbf-intro.pdf&quot;&gt;RBF的核心论文 Introduction to Radial Basis Function Networks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2_chapter14_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2_chapter14_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;matrix-factorization&quot;&gt;第15讲 Matrix Factorization&lt;/h2&gt;

&lt;p&gt;从”Linear Network” Hypothesis说起，用来做推荐，也就是根据feature x，预测得分y。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Linear-Network-Hypothesis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;求解上面的linear network，采用squared error。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear_model_for_recommendation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面的求解过程，得到Matrix factorization：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Matrix-Factorization1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具体下来，应该怎么求解呢？考虑到这里面有两个变量W和V，这时可以采用alternating minimization。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Matrix-Factorization-Learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，得到Alternating Least Squares方法。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Alternating-Least-Squares.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较一下 linear autoencoder 和 matrix factorization。linear autoencoder
≡ special matrix factorization of complete X&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Linear-Autoencoder-versus-Matrix-Factorization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面讲述了 alternating解法，matrix factorization还可以利用Stochastic gradient descent求解。SGD：most popular large-scale matrix factorization algorithm，比alternating速度更快。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/SGD-for-Matrix-Factorization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举一个SGD的例子。在KDDCup 2011 Track1中，因为该推荐任务与时间系列有关，所以在优化时，没有用stochastic GD算法，而是采用了time-deterministic GD算法，也就是最近的样本最后参与计算，这样可以保证最近的样本拟合得更好。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/KDDCup-2011-Track1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;extraction-models&quot;&gt;Extraction Models总结&lt;/h2&gt;

&lt;p&gt;将特征转换纳入到我们的学习过程。&lt;/p&gt;

&lt;p&gt;Extraction Models： neural network，RBF network，Matrix Factorization。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Map-of-Extraction-Models.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Extraction Techniques：function gradient descnet，SGD。&lt;/p&gt;

&lt;p&gt;无监督学习用于预训练，例如autoencoder，k-means clustering。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Map-of-Extraction-Techniques.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;regularization：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Pros-and-Cons-of-Extraction-Models.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;finale-&quot;&gt;第16讲 Finale 大总结&lt;/h2&gt;

&lt;p&gt;Exploiting Numerous Features via Kernel：Polynomial Kernel，Gaussian Kernel等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Exploiting-Numerous-Features-via-Kernel.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Exploiting Predictive Features via Aggregation：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Exploiting-Predictive-Features-via-Aggregation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Exploiting Hidden Features via Extraction：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Exploiting-Hidden-Features-via-Extraction.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Exploiting Low-Dim. Features via Compression：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Exploiting-Low-Dim.Features-via-Compression.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/2chapter16_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Mar 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/03/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/03/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</guid>
        
        
      </item>
    
      <item>
        <title>机器学习基石学习笔记</title>
        <description>&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;section&quot;&gt;机器学习基石 学习笔记&lt;/h1&gt;

&lt;h2 id=&quot;learning-problem&quot;&gt;第一讲 Learning problem&lt;/h2&gt;

&lt;p&gt;有用链接：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/course/ntumlone&quot;&gt;机器学习基石&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://class.coursera.org/ntumltwo-001/lecture&quot;&gt;机器学习技法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://beader.me/mlnotebook/&quot;&gt;beader.me笔记&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.douban.com/doulist/3440234/&quot;&gt;听课笔记douban&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mooc.guokr.com/course/610/機器學習基石--Machine-Learning-Foundations-/&quot;&gt;mooc学院&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;f 表示理想的方案
g 表示求解的用来预测的假设
H：假设空间
X：输入
Y：输出
D：训练集合
A：算法&lt;/p&gt;

&lt;p&gt;A takes D and H to get g。通过算法A，利用训练集合D，在假设空间H中选择最好的假设g，选择标准是g近似于f。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Formalize_the_Learning_Problem.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Practical_Definition_of_Machine_Learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter1_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;perceptron-&quot;&gt;第二讲 Perceptron-感知器&lt;/h2&gt;

&lt;p&gt;perceptron，感知器。此时h的形式为：h(x) = w*x。感知机（perceptron）是一个线性分类器(linear classifiers），线性分类器的几何表示为：直线，平面，超平面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/perceptron.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意H是infinite size；&lt;/p&gt;

&lt;p&gt;PLA(perceptron learning algorithm)，PLA A takes linear separable D and perceptrons H to get hypothesis g。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/perceptron_learning_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面，PLA算法如果D不是线性可分的，则PLA始终不能收敛。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/pocket_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与简单PLA 的区别：迭代有限次数（提前设定）；随机地寻找分错的数据（而不是循环遍历）；只有当新得到的w 比之前得到的最好的wg 还要好时，才更新wg（这里的好指的是分出来的错误更少）。
由于计算w 后要和之前的wg 比较错误率来决定是否更新wg， 所以pocket algorithm 比简单的PLA 方法要低效。&lt;/p&gt;

&lt;p&gt;更多细节请参考 &lt;a href=&quot;http://beader.me/2013/12/21/perceptron-learning-algorithm/&quot;&gt;Perceptron Learning Algorithm- PLA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter2_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter2_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter2_question3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;第三讲 机器学习的分类学&lt;/h2&gt;

&lt;p&gt;reinforcement learning：广告系统，扑克，棋类游戏。
unsupervised learning：聚类，density estimate，异常检测。
semi-supervised learning：人脸识别，医药效果检测；&lt;/p&gt;

&lt;p&gt;batch：填鸭式教学；
online：一条一条的教学；
active：sequentialliy问问题；&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Active_learning_(machine_learning)&quot;&gt;Active learning&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/types_of_learning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chater3_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;第四讲 学习的可行性分析&lt;/h2&gt;

&lt;p&gt;机器学习的可行性分析。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;对于xor问题，perceptron是无解的。所以learning is impossible。如何解决上述存在的问题？ 答：做出合理的假设。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;霍夫丁不等式(Hoeffding’s Inequality)，下式中v是样本概率；u是总体概率。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/hoeffding_inequality.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Connection to Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Connection_to_Learning1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;面对多个h 做选择时，容易出现问题。比如，某个不好的h 刚好最初的”准确“ 的假象。
随着h 的增加，出现这种假象的概率会增加。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/bound_of_baddata.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，当假设空间有限时（大小为M）时， 当N 足够大，发生BAD sample 的概率非常小。
此时学习是有效的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Statistical_Learning_Flow.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考 &lt;a href=&quot;http://beader.me/2014/01/15/is-learning-feasible/&quot;&gt;机器学习笔记-机器为何能够学习?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter4_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;第五讲 学习的可行性&lt;/h2&gt;

&lt;p&gt;学习的可能性：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;假设空间H有限（M），且训练数据足够大，则可以保证测试错误率Eout 约等于训练错误率Ein；&lt;/li&gt;
  &lt;li&gt;如果能得到Ein 接近于零，根据（1），Eout 趋向于零。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;以上两条保证的学习的可能性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter5_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;M存在重要的trade-off 思想：
（1）当M 很小，那么坏数据出现的概率非常小（见第四讲分析），学习是有效的；但是由于假设空间过小，我们不一定能找到一个方案，可以使训练误差接近零；
（2）反之，若M 很大，因为choices变多，可能找到合适的方案g使E_in(g)=0，但坏数据出现的概率会变大。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter5_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter5_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter5_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter5_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;vc&quot;&gt;第六讲-第七讲 归纳理论，VC维&lt;/h2&gt;

&lt;p&gt;关于VC维，请参考独立文章&lt;a href=&quot;http://zzbased.github.io/2015/03/07/VC维的来龙去脉.html&quot;&gt;VC维的来龙去脉&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter6_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter6_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter7_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter7_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter7_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter7_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;第八讲 噪音与错误&lt;/h2&gt;

&lt;p&gt;带权重的分类&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/weighted_classification.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;采用Pocket 方法，然而计算错误时对待两种错误(false reject/false accept) 不再一视同仁，false acceot 比false reject 严重1000倍。通过下面方法解决：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/equivalent_pocket.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;在训练开始前，我们将{(x,y)&lt;/td&gt;
      &lt;td&gt;y=-1} 的数据复制1000倍之后再开始学习，后面的步骤与传统的pocket 方法一模一样。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;然而，从效率、计算资源的角度考虑，通常不会真的将y=-1 的数据拷贝1000倍，实际中一般采用”virtual copying”。只要保证：
randomly check -1 example mistakes with 1000 times more probability.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/weighted_pocket_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考 &lt;a href=&quot;http://beader.me/2014/03/02/noise-and-error/&quot;&gt;机器学习笔记-Noise and Error&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter8_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter8_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter8_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter8_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;第九讲 线性回归&lt;/h2&gt;

&lt;p&gt;线性回归假设的思想是：寻找这样的直线/平面/超平面，使得输入数据的残差最小。
通常采用的error measure 是squared error。&lt;/p&gt;

&lt;p&gt;线性回归用矩阵表示如下:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear_regression_matrix_format.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;求导数，使导数为0，即可求得最优解&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear_regression_optim_solution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ein和Eout都向σ2(noise level)收敛，并且他们之间的差异被2(d+1)/N给bound住了。有点像VC bound，不过要比VC bound来的更严格一些。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/linear_regression_learning_curve.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个直观的想法，能否利用linear regression来做linear classification?&lt;/p&gt;

&lt;p&gt;之所以能够通过线程回归的方法来进行二值分类，是由于回归的squared error 是分类的0/1 error 的上界，我们通过优化squared error，一定程度上也能得到不错的分类结果；或者，更好的选择是，将回归方法得到的w 作为二值分类模型的初始w 值。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/0_1_loss_bound.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考 &lt;a href=&quot;http://beader.me/2014/03/09/linear-regression/&quot;&gt;机器学习笔记-Linear Regression&lt;/a&gt; &lt;a href=&quot;http://www.douban.com/note/323611077/&quot;&gt;豆瓣笔记&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter9_question1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter9_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;第十讲 逻辑回归&lt;/h2&gt;

&lt;p&gt;比较深刻的点有：&lt;/p&gt;

&lt;p&gt;似然函数的推导。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/likelihood_lr.png&quot; alt=&quot;&quot; /&gt;
推导得到Cross-Entropy Error&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/lr_algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之所以说最优的v 是与梯度相反的方向，想象一下：如果一条直线的斜率k&amp;gt;0，说明向右是上升的方向，应该向左走；反之，斜率k&amp;lt;0，向右走。&lt;/p&gt;

&lt;p&gt;解决的方向问题，步幅也很重要。步子太小的话，速度太慢；过大的话，容易发生抖动，可能到不了谷底。
显然，距离谷底较远（位置较高）时，步幅大些比较好；接近谷底时，步幅小些比较好（以免跨过界）。距离谷底的远近可以通过梯度（斜率）的数值大小间接反映，接近谷底时，坡度会减小。
因此，我们希望步幅与梯度数值大小正相关。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/learningrate_lr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考 &lt;a href=&quot;http://beader.me/2014/05/03/logistic-regression/&quot;&gt;机器学习笔记-Logistic Regression&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter10_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter10_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter10_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter10_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;第十一讲  线性分类模型&lt;/h2&gt;

&lt;p&gt;我们了解到线性回归和逻辑斯蒂回归一定程度上都可以用于线性二值分类，因为它们对应的错误衡量(square error, cross-entropy) 都是“0/1 error” 的上界。&lt;/p&gt;

&lt;p&gt;本质上讲，线性分类（感知机）、线性回归、逻辑斯蒂回归都属于线性模型，因为它们的核心都是一个线性score 函数：s=w^T*x&lt;/p&gt;

&lt;p&gt;只是三个model 对其做了不同处理：
线性分类对s 取符号；线性回归直接使用s 的值；逻辑斯蒂回归将s 映射到(0,1) 区间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/error_function_pla_lr_lr.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;多类别分类&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;方法有两个：&lt;/p&gt;

&lt;p&gt;一种直观的解决方法是将其转化为多轮的二值分类问题：任意选择一个类作为+1，其他类都看做-1，在此条件下对原数据进行训练，得到w；经过多轮训练之后，得到多个w。对于某个x，将其分到可能性最大的那个类。（例如逻辑斯蒂回归对于x 属于某个类会有一个概率估计）
如果target 是k 个类标签，我们需要k 轮训练，得到k 个w。
这种方法叫做One-Versus-All (OVA)。&lt;/p&gt;

&lt;p&gt;另一种方法叫做One-Versus-One(OVO)，对比上面的OVA 方法。
基本方法：每轮训练时，任取两个类别，一个作为+1，另一个作为-1，其他类别的数据不考虑，这样，同样用二值分类的方法进行训练；目标类有k个时，需要 k&lt;em&gt;(k-1)/2 轮训练，得到 k&lt;/em&gt;(k-1)/2 个分类器。
预测：对于某个x，用训练得到的 k*(k-1)/2 个分类器分别对其进行预测，哪个类别被预测的次数最多，就把它作为最终结果。即通过“循环赛”的方式来决定哪个“类”是冠军。&lt;/p&gt;

&lt;p&gt;OVA 和 OVO 方法的思想都很简单，可以作为以后面对多值分类问题时的备选方案，并且可以为我们提供解决问题的思路。&lt;/p&gt;

&lt;p&gt;更多请参考&lt;a href=&quot;http://www.douban.com/note/325298034/&quot;&gt;线性分类模型 (台大机器学习）&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter11_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter11_question2.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter11_question3.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chapter11_question4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-8&quot;&gt;第十二讲 非线性转换&lt;/h2&gt;

&lt;p&gt;这里的非线性转换其实也是特征转换(feature transform)，在特征工程里很常见。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/nonlinear_tranform.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;x-空间的数据转换到z-空间之后，新的假设中的参数数量也比传统线性假设多了许多。
经过非线性转换后，VC维将增大。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/nonlinear_transform_model_price.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;高次假设对数据拟合得更充分，Ein 更小；然而，由于付出的模型复杂度代价逐渐增加，Eout 并不是一直随着Ein 减小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Structured-Hypothesis-Sets.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多请参考&lt;a href=&quot;http://www.douban.com/note/325308691/&quot;&gt;笔记&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;习题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chaper12_question1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/chaper12_question2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;overfitting&quot;&gt;第十三讲 过拟合 - Overfitting&lt;/h2&gt;

&lt;p&gt;更多请参考&lt;a href=&quot;http://www.douban.com/note/325443925/&quot;&gt;笔记&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;regularization&quot;&gt;第十四讲 正规化-Regularization&lt;/h2&gt;

&lt;p&gt;原来的优化问题是NP-Hard 的。如果对w 进行更soft/smooth 的约束，可以使其更容易优化：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/Regression-with-Softer-Constraint.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;利用lagrange multiplier做regularization，得到下面式子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/augmented_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/weight_decay_regularization.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总之，lambda 越大，对应的常数C 越小，模型越倾向于选择更小的w 向量。
这种正规化成为 weight-decay regularization，它对于线性模型以及进行了非线性转换的线性假设都是有效的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;正规化与VC 理论&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据VC Bound 理论，Ein 与 Eout 的差距是模型的复杂度。也就是说，假设越复杂（dvc 越大），Eout 与 Ein 相差就越大，违背了我们学习的意愿。
对于某个复杂的假设空间H，dvc 可能很大；通过正规化，原假设空间变为正规化的假设空间H(C)。与H 相比，H(C) 是受正规化的“约束”的，因此实际上H(C) 没有H 那么大，也就是说H(C) 的VC维比原H 的VC维要小。因此，Eout 与 Ein 的差距变小。:-)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/mlfoundation_learn/l1_l2_compare.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图解释了为什么L1有稀疏解。&lt;/p&gt;

&lt;p&gt;lambda 当然不是越大越好！选择合适的lambda 也很重要，它受到随机噪音和确定性噪音的影响。&lt;/p&gt;

&lt;p&gt;更多请参考&lt;a href=&quot;http://www.douban.com/note/325451389/&quot;&gt;笔记&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;validation&quot;&gt;第十五讲 Validation&lt;/h2&gt;

&lt;h2 id=&quot;three-learning-principles&quot;&gt;第十六讲 Three Learning Principles&lt;/h2&gt;

</description>
        <pubDate>Wed, 25 Mar 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/03/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/03/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html</guid>
        
        
      </item>
    
      <item>
        <title>VC维的来龙去脉</title>
        <description>&lt;h1 id=&quot;vc&quot;&gt;VC维的来龙去脉&lt;/h1&gt;

&lt;h4 id=&quot;author-vincentyaotencentcom&quot;&gt;author: vincentyao@tencent.com&lt;/h4&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;目录：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;说说历史&lt;/li&gt;
  &lt;li&gt;Hoeffding不等式&lt;/li&gt;
  &lt;li&gt;Connection to Learning&lt;/li&gt;
  &lt;li&gt;学习可行的两个核心条件&lt;/li&gt;
  &lt;li&gt;Effective Number of Hypotheses&lt;/li&gt;
  &lt;li&gt;Growth Function&lt;/li&gt;
  &lt;li&gt;Break Point与Shatter&lt;/li&gt;
  &lt;li&gt;VC Bound&lt;/li&gt;
  &lt;li&gt;VC dimension&lt;/li&gt;
  &lt;li&gt;深度学习与VC维&lt;/li&gt;
  &lt;li&gt;小结&lt;/li&gt;
  &lt;li&gt;参考文献&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;VC维在机器学习领域是一个很基础的概念，它给诸多机器学习方法的可学习性提供了坚实的理论基础，但有时候，特别是对我们工程师而言，SVM，LR，深度学习等可能都已经用到线上了，但却不理解VC维。&lt;/p&gt;

&lt;p&gt;这里，在台湾大学&lt;a href=&quot;https://www.coursera.org/course/ntumlone&quot;&gt;机器学习基石&lt;/a&gt;课程的基础上，我们简单聊聊”VC维的来龙去脉”。我们将解决以下问题：为什么某机器学习方法是可学习的？为什么会有过拟合？拿什么来衡量机器学习模型的复杂度？深度学习与VC维的关系？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;说说历史&lt;/h2&gt;
&lt;p&gt;在讲VC维之前，我们不妨来说说VC维的历史。而说起VC维的历史，又不得不提起神经网络，一方面是因为神经网络与VC维的发明过程是交织在一起的，另一方面是由于神经网络乏善可陈的泛化控制方法，深度学习在理论基础上一直被怀疑，甚至神经网络和VC维的代表SVM还一起争风吃醋过好多年。&lt;/p&gt;

&lt;p&gt;1943年，模拟神经网络由麦卡洛可（McCulloch）和皮茨（Pitts)提出，他们分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。&lt;/p&gt;

&lt;p&gt;1957年，康奈尔大学的实验心理学家弗兰克·罗森布拉特(Rosenblatt)在一台IBM-704计算机上模拟实现了一种他发明的叫作”感知机”（Perceptron）的神经网络模型。神经网络与支持向量机都源自于感知机（Perceptron）。&lt;/p&gt;

&lt;p&gt;1962年，罗森布拉特著作：《神经动力学原理：感知机和大脑机制的理论》（Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms）。&lt;/p&gt;

&lt;p&gt;1969年，明斯基和麻省理工学院的另一位教授佩普特合作著作：《感知机：计算几何学》（Perceptrons: An Introduction to Computational Geometry)。在书中，明斯基和佩普特证明单层神经网络不能解决XOR（异或）问题。&lt;/p&gt;

&lt;p&gt;1971年，V. Vapnik and A. Chervonenkis在论文”On the uniform convergence of relative frequencies of events to their probabilities”中提出&lt;strong&gt;VC维&lt;/strong&gt;的概念。&lt;/p&gt;

&lt;p&gt;1974年，V. Vapnik提出了结构风险最小化原则。&lt;/p&gt;

&lt;p&gt;1974年，沃波斯（Werbos）的博士论文证明了在神经网络多加一层，并且利用“后向传播”（Back-propagation）学习方法，可以解决XOR问题。那时正是神经网络研究的低谷，文章不合时宜。&lt;/p&gt;

&lt;p&gt;1982年，在加州理工担任生物物理教授的霍普菲尔德，提出了一种新的神经网络，可以解决一大类模式识别问题，还可以给出一类组合优化问题的近似解。这种神经网络模型后被称为霍普菲尔德网络。&lt;/p&gt;

&lt;p&gt;1986年，Rummelhart与McClelland发明了神经网络的学习算法Back Propagation。&lt;/p&gt;

&lt;p&gt;1993年，Corinna Cortes和Vapnik等人提出了支持向量机(support vector machine)。神经网络是多层的非线性模型，支持向量机利用核技巧把非线性问题转换成线性问题。&lt;/p&gt;

&lt;p&gt;1992\~2005年，SVM与Neural network之争，但被互联网风潮掩盖住了。&lt;/p&gt;

&lt;p&gt;2006年，Hinton提出神经网络的Deep Learning算法。Deep Learning假设神经网络是多层的，首先用Restricted Boltzmann Machine（非监督学习）学习网络的结构，然后再通过Back Propagation（监督学习）学习网络的权值。&lt;/p&gt;

&lt;p&gt;现在，deep learning的应用越来越广泛，甚至已经有超越SVM的趋势。一方面以Hinton，Lecun为首的深度学习派坚信其有效实用性，另一方面Vapnik等统计机器学习理论专家又坚持着理论阵地，怀疑deep learning的泛化界。&lt;/p&gt;

&lt;h2 id=&quot;hoeffding&quot;&gt;Hoeffding不等式&lt;/h2&gt;

&lt;p&gt;Hoeffding不等式是关于一组随机变量均值的概率不等式。
如果\(X_1,X_2,\cdots,X_n\)为一组独立同分布的参数为p的伯努利分布随机变量，n为随机变量的个数。定义这组随机变量的均值为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar X=\frac{X_1+X_2+\cdots+X_n}{n}&lt;/script&gt;

&lt;p&gt;对于任意\(\delta&amp;gt;0\), Hoeffding不等式可以表示为&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(|\bar X - E(\bar X)| \geq \delta) \leq \exp(-2\delta^2n^2)&lt;/script&gt;

&lt;p&gt;更多请参考:&lt;a href=&quot;http://science.scileaf.com/library/2461&quot;&gt;Hoeffding不等式&lt;/a&gt;，&lt;a href=&quot;http://zh.wikipedia.org/zh-cn/集中不等式&quot;&gt;集中不等式&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;case示例&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;在统计推断中，我们可以利用样本的统计量(statistic)来推断总体的参数(parameter)，譬如使用样本均值来估计总体期望。如下图所示，我们从罐子里抽球，希望估计罐子里红球和绿球的比例。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/bin_sample.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;直觉上，如果我们有更多的样本(抽出更多的球)，则样本期望\(\nu\)应该越来越接近总体期望\(\mu\)。事实上，这里可以用hoeffding不等式表示如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/bin_sample_hoeffding.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从hoeffding不等式可以看出，当n逐渐变大时，不等式的UpperBound越来越接近0，所以样本期望越来越接近总体期望。&lt;/p&gt;

&lt;h2 id=&quot;connection-to-learning&quot;&gt;Connection to Learning&lt;/h2&gt;

&lt;p&gt;接下来，我们希望可以将机器学习关联到上一节讨论的hoeffding不等式。&lt;/p&gt;

&lt;p&gt;一个基本的机器学习过程如下图所示。其中的概念定义为：
f 表示理想的方案(可以是一个函数，也可以是一个分布)，H 是该机器学习方法的假设空间，g 表示我们求解的用来预测的假设，g属于H。&lt;/p&gt;

&lt;p&gt;机器学习的过程就是：通过算法A，在假设空间H中，根据样本集D，选择最好的假设作为g。选择标准是 g 近似于 f。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/setup_of_the_learning_problem_add_components.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;拿&lt;a href=&quot;http://zh.wikipedia.org/zh/感知器&quot;&gt;perceptron&lt;/a&gt;来举例。&lt;/p&gt;

&lt;p&gt;感知机（perceptron）是一个线性分类器(linear classifiers）。
线性分类器的几何表示：直线、平面、超平面。&lt;/p&gt;

&lt;p&gt;perceptron的假设空间，用公式描述，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/perceptron_formula.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;感知器的优化目标如下式所示，w_g就是我们要求的最好的假设。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/perceptron_optim.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;设定两个变量，如下图所示，图中 f(x)表示理想目标函数，h(x)是我们预估得到的某一个目标函数，h(x)是假设空间H中的一个假设。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Eout(h)&lt;/strong&gt;，可以理解为在理想情况下(已知f)，总体(out-of-sample)的损失(这里是0-1 loss)的期望，称作expected loss。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ein(h)&lt;/strong&gt;，可以理解为在训练样本上(in-of-sample)，损失的期望，称作expirical loss。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/learning_hoeffding.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当训练样本量N足够大，且样本是独立同分布的，类比于上面”抽球”的例子，可以通过样本集上的expirical loss Ein(h) 推测总体的expected loss Eout(h)。基于hoeffding不等式，我们得到下面式子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/learning_hoeffding2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根据上面不等式，我们可以推断，当N足够大时，expected loss和expirical loss将非常接近。&lt;/p&gt;

&lt;p&gt;注意在上面推导中，我们是针对某一个特定的解h(x)。在我们的假设空间H中，往往有很多个假设函数(甚至于无穷多个)，这里我们先假定H中有M个假设函数。&lt;/p&gt;

&lt;p&gt;那么对于整个假设空间，也就是这M个假设函数，可以推导出下面不等式：&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(|E_{in}(h_1)-E_{out}(h_1)|&gt;\epsilon  \cup |E_{in}(h_2)-E_{out}(h_2)| &gt; \epsilon   ... |E_{in}(h_m)-E_{out}(h_m)|&gt;\epsilon)&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\leq P(|E_{in}(h_1)-E_{out}(h_1)|&gt;\epsilon) + P(|E_{in}(h_2)-E_{out}(h_2)|&gt;\epsilon) + ... + P(|E_{in}(h_m)-E_{out}(h_m)|&gt;\epsilon)&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\leq 2M\exp(-2 \epsilon^2 N)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;上面式子的含义是：在假设空间H中，设定一个较小的\(\epsilon\)值，任意一个假设h，它的Ein(h)与Eout(h)的差由该值\(2M\exp(-2 \epsilon^2 N)\)所约束住。注意这个bound值与 “样本数N和假设数M” 密切相关。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;学习可行的两个核心条件&lt;/h2&gt;

&lt;p&gt;在往下继续推导前，先看一下&lt;strong&gt;什么情况下Learning是可行的&lt;/strong&gt;？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果假设空间H的size M是有限的，当N足够大时，那么对假设空间中任意一个g，Eout(g)约等于Ein(g)；&lt;/li&gt;
  &lt;li&gt;利用算法A从假设空间H中，挑选出一个g，使得Ein(g)接近于0，那么&lt;a href=&quot;http://en.wikipedia.org/wiki/Probably_approximately_correct_learning&quot;&gt;probably approximately correct&lt;/a&gt;而言，Eout(g)也接近为0；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/two_central_questions.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面这两个核心条件，也正好对应着test和train这两个过程。train过程希望损失期望(即Ein(g) )尽可能小；test过程希望在真实环境中的损失期望也尽可能小，即Ein(g)接近于Eout(g)。&lt;/p&gt;

&lt;p&gt;但往往我们更多在关心，如何基于模型的假设空间，利用最优化算法，找到Ein最小的解g。但容易忽视test这个过程，如果让学习可行，不仅仅是要在训练集表现好，在真实环境里也要表现好。&lt;/p&gt;

&lt;p&gt;从上述推导出来的不等式，我们看到假设数M 在这两个核心条件中有着重要作用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/trade_off_on_M.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;M太小，当N足够大时，Ein和Eout比较接近，但如果候选假设集太小，不容易在其中找到一个g，使得Ein(g)约等于0，第二项不能满足。而如果M太大，这时候选集多了，相对容易在其中找到一个g，使得Ein(g)约等于0，但第一项就不能满足了。所以假设空间H的大小M很关键。&lt;/p&gt;

&lt;p&gt;对于一个假设空间，M可能是无穷大的。要能够继续推导下去，那么有一个直观的思路，能否找到一个有限的因子m_H来替代不等式bound中的M。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/finite_quantity.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;虽说假设空间很大，上述推导里，我们用到了P(h1 or h2 … hm) &amp;lt;= P(h1) + P(h2) + … + P(hm)。但事实上，多个h之间并不是完全独立的，他们是有很大的重叠的，也就是在M个假设中，可能有一些假设可以归为同一类。&lt;/p&gt;

&lt;p&gt;下面我们以二维假设空间为例，来解释一下该空间下各假设在确定的训练样本上的重叠性。&lt;/p&gt;

&lt;p&gt;举例来说，如果我们的算法要在平面上(二维空间)挑选一条直线方程作为g，用来划分一个点x1。假设空间H是所有的直线，它的size M是无限多的。但是实际上可以将这些直线分为两类，一类是把x1判断为正例的，另一类是把x1判断为负例的。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/1point2lines.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那如果在平面上有两个数据点x1,x2，这样的话，假设空间H中的无数条直线可以分为4类。那依次类推，3个数据点情况下，H中最多有8类直线。4个数据点，H中最多有14类直线(注意：为什么不是16类直线)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/4points14lines.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上面在二维假设空间中的分析，我们可以推测到一个结论，假设空间size M是很大，但在样本集D上，有效的假设函数数目是有限的。接下来我们将继续推导这个有效的假设函数值。&lt;/p&gt;

&lt;h2 id=&quot;effective-number-of-hypotheses&quot;&gt;Effective Number of Hypotheses&lt;/h2&gt;

&lt;p&gt;对于这个有效的假设函数值，我们尝试用一个数学定义来说明：&lt;/p&gt;

&lt;p&gt;从H中任意选择一个方程h，让这个h对样本集合D进行二元分类，输出一个结果向量。例如在平面里用一条直线对2个点进行二元分类，输出可能为{1,-1}，{-1,1}，{1,1}，{-1,-1}，这样每个输出向量我们称为一个dichotomy。&lt;/p&gt;

&lt;p&gt;下面是hypotheses与dichotomies的概念对比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/dichotomies.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意到，如果对平面上的4个点来分类，根据前面分析，输出的结果向量只有14种可能，即有14个dichotomies。&lt;/p&gt;

&lt;p&gt;如果有N个样本数据，那么有效的假设个数定义为：
effective(N) = H作用于样本集D”最多”能产生多少不同的dichotomy。&lt;/p&gt;

&lt;p&gt;所以有一个直观思路，能否用effective(N)来替换hoeffding不等式中的M。接下来我们来分析下effective(N)。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/finite_effective_n.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;growth-function&quot;&gt;Growth Function&lt;/h2&gt;

&lt;p&gt;H作用于D”最多”能产生多少种不同的dichotomies？这个数量与假设空间H有关，跟数据量N也有关。将H作用于D”最多”能产生的dichotomies数量(即effective(N) )表示为数学符号：max_H(x1,x2,…,xN)&lt;/p&gt;

&lt;p&gt;这个式子又称为”成长函数”(growth function)。在H确定的情况下，growth function是一个与N相关的函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/growth_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下图举4个例子，分别计算其growth function：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/growth_function_4case.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于第一个例子，positive ray，相当于是正向的射线。该假设空间，作用于1个样本点，可以产生2种dichotomies：(-1)，(+1)。作用于2个样本点，可以产生3种dichotomies：(-1,+1)，(-1,-1)，(+1,+1)。作用于3个样本点，可以产生4种dichotomies。依次类推，可以推导出其成长函数 m_H(N)=N+1；&lt;/p&gt;

&lt;p&gt;求解出m_H(N)后，那是不是可以考虑用m_H(N)替换M? 如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/growth_function_replace_m.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;break-pointshatter&quot;&gt;Break Point与Shatter&lt;/h2&gt;

&lt;p&gt;在进一步推导前，再看两个概念：shatter，break point。&lt;/p&gt;

&lt;p&gt;Shatter的概念：当假设空间H作用于N个input的样本集时，产生的dichotomies数量等于这N个点总的组合数\(2^N\)是，就称：这N个inputs被H给shatter掉了。&lt;/p&gt;

&lt;p&gt;要注意到 shatter 的原意是”打碎”，在此指”N个点的所有(碎片般的)可能情形都被H产生了”。所以\( m_H(N)=2^N \)的情形是即为”shatter”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/break_point.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于给定的成长函数m_H(N)，从N=1出发，N慢慢变大，当增大到k时，出现\(m_H(N) &amp;lt; 2^k\)的情形，则我们说k是该成长函数的&lt;strong&gt;break point&lt;/strong&gt;。对于任何N &amp;gt; k个inputs而言，H都没有办法再shatter他们了。&lt;/p&gt;

&lt;p&gt;举例来说，对于上面的positive ray的例子，因为m_H(N)=N+1，当N=2时，m_H(2)&amp;lt;2^2， 所以它的break point就是2。&lt;/p&gt;

&lt;h2 id=&quot;vc-bound&quot;&gt;VC Bound&lt;/h2&gt;

&lt;p&gt;说完break point的概念后，再回到成长函数。&lt;/p&gt;

&lt;p&gt;我们将成长函数的上界，设为B(N,k)，意为：maximum possible m_H(N) when break point = k。&lt;/p&gt;

&lt;p&gt;那么我们做一些简单的推导：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;B(2,2)=3。因为break point=2，任意两个点都不能被shatter，m_H(2)肯定小于2^2，所以B(2,2)=3。&lt;/li&gt;
  &lt;li&gt;B(3,2)=4。因为任意两个点都不能被shatter，那么3个点产生的dichotomies不能超过4，所以B(3,2)=4。&lt;/li&gt;
  &lt;li&gt;B(N,1)=1。&lt;/li&gt;
  &lt;li&gt;B(N,k)=2^N for N &amp;lt; k；B(N,k)=2^N-1 for N=k；&lt;/li&gt;
  &lt;li&gt;B(4,3)=？去掉其中的一个数据点x4后，考虑到break point=3，余下数据(x1,x2,x3)的dichotomies数目不能超过B(3,3)。当扩展为(x1,x2,x3,x4)时，(x1,x2,x3)上的dichotomies只有部分被重复复制了，设被复制的dichotomies数量为a，未被复制的数量为b。于是有B(3,3) = a+b;  B(4,3) = 2&lt;em&gt;a + b。因为a被复制了，表示x4有两个取值，那么(x1,x2,x3)上的a应该小于等于B(3,2)。所以推导出B(4,3) = 2&lt;/em&gt;a + b &amp;lt;= B(3,3) + B(3,2)。&lt;/li&gt;
  &lt;li&gt;对于任意N&amp;gt;k，类推可以得到，B(N,k) ≤ B(N−1,k)+B(N−1,k−1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;最后利用数学归纳法，可以证明得到下面的bounding function(N&amp;gt;k)：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_H(N) \leq \sum_{i=0}^{k−1}{N \choose i}&lt;/script&gt;

&lt;p&gt;这个式子显然是多项式的，多项式的最高幂次项为：N^(k-1)。&lt;/p&gt;

&lt;p&gt;所以我们得到结论：如果break point存在（有限的正整数），生长函数m(N) 是多项式的。&lt;/p&gt;

&lt;p&gt;再重复一遍，H作用于数据量为N的样本集D，方程的数量看上去是无穷的，但真正有效(effective)的方程的数量却是有限的，这个数量为m_H(N)。H中每一个h作用于D都能算出一个Ein来，一共有m_H(N)个不同的Ein。&lt;/p&gt;

&lt;p&gt;OK，到目前为止，关于m_H(N)的推导结束。回到growth function小节提出的问题，能否用&lt;strong&gt;m_H(N)直接替换M?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;既然得到了m(N)的多项式上界，我们希望对之前的不等式中M 进行替换，用m_H(N)来替换M。这样替换后，当break point存在时，N足够大时，该上界是有限的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/replace_vc_bound.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然而直接替换是存在问题的，主要问题是：Ein的可能取值是有限个的，但Eout的可能取值是无限的。可以通过将Eout 替换为验证集(verification set) 的Ein’ 来解决这个问题。
下面是推导过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_bound_step1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_bound_step2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_bound_step3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后我们得到下面的VC bound:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_bound1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于这个公式的数学推导，我们可以暂且不去深究。我们先看一下这个式子的意义，如果假设空间存在有限的break point，那么m_H(2N)会被最高幂次为k-1的多项式上界给约束住。随着N的逐渐增大，指数式的下降会比多项式的增长更快，所以此时VC Bound是有限的。更深的意义在于，N足够大时，对H中的任意一个假设h，Ein(h)都将接近于Eout(h)，这表示学习可行的第一个条件是有可能成立的。&lt;/p&gt;

&lt;h2 id=&quot;vc-dimension&quot;&gt;VC dimension&lt;/h2&gt;

&lt;p&gt;说了这么多，VC维终于露出庐山真面目了。此概念由Vladimir Vapnik与Alexey Chervonenkis提出。&lt;/p&gt;

&lt;p&gt;一个假设空间H的&lt;strong&gt;VC dimension&lt;/strong&gt;，是这个H最多能够shatter掉的点的数量，记为\(d&lt;em&gt;{vc}(H)\)。如果不管多少个点H都能shatter它们，则\(d&lt;/em&gt;{vc}(H)\)=无穷大。还可以理解为：vc-dim就是argmax_n {growth function=power(2,n)}。&lt;/p&gt;

&lt;p&gt;根据定义，可以得到一个明显的结论：&lt;script type=&quot;math/tex&quot;&gt; k = d_{vc}(H) + 1 &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;根据前面的推导，我们知道VC维的大小：与学习算法A无关，与输入变量X的分布也无关，与我们求解的目标函数f 无关。它只与模型和假设空间有关。&lt;/p&gt;

&lt;p&gt;我们已经分析了，对于2维的perceptron，它不能shatter 4个样本点，所以它的VC维是3。此时，我们可以分析下2维的perceptron，如果样本集是线性可分的，perceptron learning algorithm可以在假设空间里找到一条直线，使Ein(g)=0；另外由于其VC维=3，当N足够大的时候，可以推断出：Eout(g)约等于Ein(g)。这样学习可行的两个条件都满足了，也就证明了2维感知器是可学习的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/pla_revised.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结回顾一下，要想让机器学到东西，并且学得好，有2个条件：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;H的d_vc是有限的，这样VC bound才存在。(good H)；N足够大(对于特定的d_vc而言)，这样才能保证vc bound不等式的bound不会太大。(good D)&lt;/li&gt;
  &lt;li&gt;算法A有办法在H中顺利的挑选一个使得Ein最小的g。(good A)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;回到最开始提出的学习可行的两个核心条件，尝试用VC维来解释：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/m_and_d_vc.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看出，当VC维很小时，条件1容易满足，但因为假设空间较小，可能不容易找到合适的g 使得Ein(g)约等于0。当VC维很大时，条件2容易满足，但条件1不容易满足，因为VC bound很大。&lt;/p&gt;

&lt;p&gt;VC维反映了假设空间H 的强大程度(powerfulness)，VC 维越大，H也越强，因为它可以打散(shatter)更多的点。&lt;/p&gt;

&lt;p&gt;定义模型自由度是，模型当中可以自由变动的参数的个数，即我们的机器需要通过学习来决定模型参数的个数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/degree_of_freedom.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一个实践规律：VC 维与假设参数w 的自由变量数目大约相等。dVC = #free parameters。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_practical_rule.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们将原不等式做一个改写，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_power1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面式子中的第3项表示模型复杂度。模型越复杂，VC维大，Eout 可能距离Ein 越远。如下图所示，随着d_vc的上升，E_in不断降低，而模型复杂度不断上升。&lt;/p&gt;

&lt;p&gt;它们的上升与下降的速度在每个阶段都是不同的，因此我们能够寻找一个二者兼顾的，比较合适的d_vc，用来决定应该使用多复杂的模型。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/vc_power2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型较复杂时(d_vc 较大)，需要更多的训练数据。 理论上，数据规模N 约等于 10000*d_vc（称为采样复杂性，sample complexity）；然而，实际经验是，只需要 N = 10*d_vc。
造成理论值与实际值之差如此之大的最大原因是，VC Bound 过于宽松了，我们得到的是一个比实际大得多的上界。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/n_practical_rule.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意在前述讨论中，理想的目标函数为f(x)，error measure用的是”0-1 loss”。如果在unknown target上引入噪声(+noise)，或者用不同的error measure方法，VC theory还有效吗？这里只给出结论，VC theory对于绝大部分假设空间(or 加入噪声)和error度量方法，都是有效的。&lt;/p&gt;

&lt;p&gt;除此外，我们为了避免overfit，一般都会加正则项。那加了正则项后，新的假设空间会得到一些限制，此时新假设空间的VC维将变小，也就是同样训练数据条件下，Ein更有可能等于Eout，所以泛化能力更强。这里从VC维的角度解释了正则项的作用。&lt;/p&gt;

&lt;h2 id=&quot;vc-1&quot;&gt;深度学习与VC维&lt;/h2&gt;

&lt;p&gt;对于神经网络，其VC维的公式为：&lt;/p&gt;

&lt;p&gt;dVC = O(VD)，其中V表示神经网络中神经元的个数，D表示weight的个数，也就是神经元之间连接的数目。(注意：此式是一个较粗略的估计，深度神经网络目前没有明确的vc bound)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/other/VC理论/neural_network_vc_dimension.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举例来说，一个普通的三层全连接神经网络：input layer是1000维，hidden layer有1000个nodes，output layer为1个node，则它的VC维大约为O(1000*1000*1000)。&lt;/p&gt;

&lt;p&gt;可以看到，神经网络的VC维相对较高，因而它的表达能力非常强，可以用来处理任何复杂的分类问题。根据上一节的结论，要充分训练该神经网络，所需样本量为10倍的VC维。如此大的训练数据量，是不可能达到的。所以在20世纪，复杂神经网络模型在out of sample的表现不是很好，容易overfit。&lt;/p&gt;

&lt;p&gt;但现在为什么深度学习的表现越来越好。原因是多方面的，主要体现在：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;通过修改神经网络模型的结构，以及提出新的regularization方法，使得神经网络模型的VC维相对减小了。例如卷积神经网络，通过修改模型结构(局部感受野和权值共享)，减少了参数个数，降低了VC维。2012年的AlexNet，8层网络，参数个数只有60M；而2014年的&lt;a href=&quot;http://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf&quot;&gt;GoogLeNet&lt;/a&gt;，22层网络，参数个数只有7M。再例如dropout，drop connect，denosing等regularization方法的提出，也一定程度上增加了神经网络的泛化能力。&lt;/li&gt;
  &lt;li&gt;训练数据变多了。随着互联网的越来越普及，相比于以前，训练数据的获取容易程度以及量和质都大大提升了。训练数据越多，Ein越容易接近于Eout。而且目前训练神经网络，还会用到很多data augmentation方法，例如在图像上，剪裁，平移，旋转，调亮度，调饱和度，调对比度等都使用上了。&lt;/li&gt;
  &lt;li&gt;除此外，pre-training方法的提出，GPU的利用，都促进了深度学习。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但即便这样，深度学习的VC维和VC Bound依旧很大，其泛化控制方法依然没有强理论支撑。但是实践又一次次证明，深度学习是好用的。所以VC维对深度学习的指导意义，目前不好表述，有一种思想建议，深度学习应该抛弃对VC维之类概念的迷信，尝试从其他方面来解释其可学习型，例如使用泛函空间（如&lt;a href=&quot;http://en.wikipedia.org/wiki/Banach_space&quot;&gt;Banach Space&lt;/a&gt;）中的概率论。&lt;/p&gt;

&lt;p&gt;更多细节请参考下面链接：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://ttic.uchicago.edu/~tewari/lectures/lecture12.pdf&quot;&gt;VC Dimension of Multilayer Neural Networks&lt;/a&gt;，该文章给出了多层神经网络的VC bound的相关证明。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.kdnuggets.com/2014/02/exclusive-yann-lecun-deep-learning-facebook-ai-lab.html&quot;&gt;Lecun: What is the relationship between Deep Learning and Support Vector Machines / Statistical Learning Theory? &lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;Vapnik really believes in his bounds. He worried that neural nets didn’t have similarly good ways to do capacity control (although neural nets do have generalization bounds, since they have finite VC dimension).&lt;/p&gt;

    &lt;p&gt;Lecun’s counter argument was that the ability to do capacity control was somewhat secondary to the ability to compute highly complex function with a limited amount of computation.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;小结&lt;/h2&gt;

&lt;p&gt;上面仔细分析了VC维的来龙去脉，讲述了VC维在机器学习理论中的指导意义。考虑到VC维在机器学习领域虽是基础，却也是大坑，所以难免有理解不深或不当之处，敬请谅解。若希望获得更深理解，请参考下面的参考文献。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;参考文献&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.autonlab.org/tutorials/vcdim.html&quot;&gt;VC dimension Tutorial Slides by Andrew Moore&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/course/ntumlone&quot;&gt;机器学习基石&lt;/a&gt; (上文的截图均出自于该课程的讲义) &lt;a href=&quot;http://www.douban.com/doulist/3381853/&quot;&gt;笔记&lt;/a&gt; &lt;a href=&quot;http://beader.me/mlnotebook/section2/vc-dimension-three.html&quot;&gt;笔记2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.svms.org/vc-dimension/&quot;&gt;vc-dimension in svms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.36dsj.com/archives/21236&quot;&gt;机器学习简史&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory&quot;&gt;Vapnik–Chervonenkis theory&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf&quot;&gt;Deep Learning Tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zhihu.com/question/27434103&quot;&gt;深度学习的研究领域是否有被过度夸大&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://freemind.pluskid.org/slt/vc-theory-vapnik-chervonenkis-dimension&quot;&gt;VC Theory: Vapnik–Chervonenkis Dimension&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://1.guzili.sinaapp.com/?p=174&quot;&gt;深度学习与统计学习理论&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 07 Mar 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/03/07/VC%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/03/07/VC%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89.html</guid>
        
        
      </item>
    
      <item>
        <title>语音识别</title>
        <description>&lt;p&gt;最近，组里新来了一个博士同学。他的博士专业是语音识别，正好跟我们分享了一下语义识别相关的知识点。老早前，我就看过DengLi在微软的文章，结合肖博的分享，正好可以把语音识别相关的东东，在脑子里串起来梳理下，特撰文如下。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;语音识别&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/38131.pdf&quot;&gt;Deep Neural Networks for Acoustic Modeling in Speech Recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://msr-waypoint.com/pubs/188864/ICASSP-2013-OverviewMSRDeepLearning.pdf&quot;&gt;RECENT ADVANCES IN DEEP LEARNING FOR SPEECH RESEARCH AT MICROSOFT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://research.microsoft.com/pubs/144412/dbn4lvcsr-transaslp.pdf&quot;&gt;Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://arxiv.org/pdf/1412.5567v2.pdf&quot;&gt;Deep Speech: Scaling up end-to-end speech recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/21815490&quot;&gt;为什么 Deep Learning 最先在语音识别和图像处理领域取得突破？&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;DL 适合处理感知, 而非逻辑；
感知与逻辑的重要区别在于输入数据在输入空间中做连续变化还是离散变化；
神经生物学上对人脑的逻辑还理解的不够, 对感知理解的好一些所以糙出了DL；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/20398418&quot;&gt;语音识别的技术原理是什么&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;信号处理及特征提取模块。该模块的主要任务是从输入信号中提取特征，供声学模型处理。同时，它一般也包括了一些信号处理技术，以尽可能降低环境噪声、信道、说话人等因素对特征造成的影响。&lt;/p&gt;

        &lt;p&gt;主要有：降噪和分帧。分帧就是把波形切开成一小段一小段，每小段称为一帧。分帧操作通常使用移动窗函数来实现，分帧之前还要做一些预加重等操作，帧与帧之间是有交叠的。&lt;/p&gt;

        &lt;p&gt;分帧后，语音就变成了很多小段。这时需要对这些时域波形做波形变换，常见的一种变换方法是提取MFCC特征，把每一帧波形变成一个12维向量。MFCC的计算首先用FFT将时域信号转化成频域，之后对其对数能量谱用依照Mel刻度分布的三角滤波器组进行卷积，最后对各个滤波器的输出构成的向量进行离散余弦变换DCT，取前N个系数。&lt;/p&gt;

        &lt;p&gt;通常的特征有：线性预测系数LPC，倒谱系数CEP，梅尔频率倒谱系数MFCC，感知线性预测PLP。&lt;/p&gt;

        &lt;p&gt;经过该模块处理后，声音就成了一个12行（假设声学特征是12维）、N列的一个矩阵，称之为观察序列，这里N为总帧数。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;再介绍三个概念&lt;/p&gt;

        &lt;p&gt;单词：英语中就是单词，汉语中是汉字。
音素：单词的发音由音素构成。对英语，一种常用的音素集是卡内基梅隆大学的一套由39个音素构成的音素集，参见The CMU Pronouncing Dictionary‎。汉语一般直接用全部声母和韵母作为音素集，另外汉语识别还分有调无调。
状态：比音素更细致的语音单位。通常一个音素由3个状态构成。&lt;/p&gt;

        &lt;p&gt;接下来，语音识别是怎么工作的呢？
第一步，把帧识别成状态（难点）。
第二步，把状态组合成音素。
第三步，把音素组合成单词。&lt;/p&gt;

        &lt;p&gt;语音识别系统的模型通常由声学模型和语言模型两部分组成，分别对应于语音到音节概率的计算和音节到字概率的计算。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;统计声学模型。典型系统多采用基于一阶隐马尔科夫模型进行建模。&lt;/p&gt;

        &lt;p&gt;如何把帧识别成状态，可以看某帧对应哪个状态的概率最大，那这帧就属于哪个状态，这叫做“最大似然”。
声学模型，里面存了一大堆参数，通过这些参数，就可以知道帧和状态对应的概率。&lt;/p&gt;

        &lt;p&gt;使用隐马尔可夫模型（Hidden Markov Model，HMM），第一步，构建一个状态网络。第二步，从状态网络中寻找与声音最匹配的路径。
首先构造单词级网络，然后展开成音素网络，然后展开成状态网络。然后在状态网络中搜索一条最佳路径，这条路径和语音之间的概率（称之为累积概率）最大。搜索的算法是一种动态规划剪枝的算法，称之为Viterbi算法，用于寻找全局最优路径。&lt;/p&gt;

        &lt;p&gt;这里所说的累积概率，由三部分构成，分别是：
观察概率：每帧和每个状态对应的概率；
转移概率：每个状态转移到自身或转移到下个状态的概率；
语言概率：根据语言统计规律得到的概率；
其中，前两种概率从声学模型中获取，最后一种概率从语言模型中获取。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;发音词典。发音词典包含系统所能处理的词汇集及其发音。发音词典实际提供了声学模型建模单元与语言模型建模单元间的映射。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;语言模型。语言模型对系统所针对的语言进行建模。理论上，包括正则语言，上下文无关文法在内的各种语言模型都可以作为语言模型，但目前各种系统普遍采用的还是基于统计的N元文法及其变体。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;解码器。解码器是语音识别系统的核心之一，其任务是对输入的信号，根据声学、语言模型及词典，寻找能够以最大概率输出该信号的词串。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 27 Feb 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/02/27/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/02/27/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB.html</guid>
        
        
      </item>
    
      <item>
        <title>深度学习相关笔记</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;神经网络基础&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://hahack.com/reading/ann1/&quot;&gt;漫谈ANN(1)：M-P模型&lt;/a&gt;，&lt;a href=&quot;http://hahack.com/reading/ann2/&quot;&gt;漫谈ANN(2)：BP神经网络&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;M-P模型:1943年心理学家W.McCulloch和数学家W.Pitts合作提出了这个模型，所以取了他们两个人的名字（McCulloch-Pitts）&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/mp_model.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Perceptron: 在1958年,美国心理学家Frank Rosenblatt,基于M-P模型的结构,提出一种具有单层计算单元的神经网络,称为感知器(Perceptron)。&lt;/p&gt;

    &lt;p&gt;单层感知器不能解决非线性问题，譬如”异或”。Kolmogorov理论指出：双隐层感知器就足以解决任何复杂的分类问题。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://deeplearning.stanford.edu/wiki/index.php/神经网络&quot;&gt;UFLDL-神经网络&lt;/a&gt;, &lt;a href=&quot;http://deeplearning.stanford.edu/wiki/index.php/反向传导算法&quot;&gt;反向传播算法-详解&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://stats.stackexchange.com/questions/106334/cost-function-of-neural-network-is-non-convex&quot;&gt;为什么多层神经网络是非凸函数&lt;/a&gt; 这里有解释，简单点说，如果交换某一层某两个nodes和weights以及相应连接的nodes，将得到a different set of parameters，但是cost function是一样的，所以是非凸的。&lt;/p&gt;

    &lt;p&gt;神经网络参数必须随机初始化，而不是全部置为0。如果所有参数都用相同的值作为初始值，那么所有隐藏层单元最终会得到与输入值有关的、相同的函数。随机初始化的目的是使对称失效。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.sina.com.cn/s/blog_71329a960102v1eo.html&quot;&gt;神经网络历史&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.hcii-lab.net/lianwen/Course/Machine%20Learning/&quot;&gt;金连文教授-机器学习课程&lt;/a&gt;，课程中神经网络相关的章节很好。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[文章]《10 Common Misconceptions about Neural Networks》http://t.cn/RZMtCsP 神经网络十大认识误区，作者是Stuart Gordon Reid，值得一读&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;深度学习综述&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://deeplearning.net/tutorial/deeplearning.pdf&quot;&gt;Deep Learning Tutorial. LISA lab, University of Montreal&lt;/a&gt;  &lt;a href=&quot;http://deeplearning.net/software_links/&quot;&gt;software&lt;/a&gt;
基于Theano的深度学习教程，内容很新，包括了多层感知器，卷积神经网络，auto encoder，RBM，Deep Belief Networks，Monte-carlo sampling，循环神经网络，LSTM，RNN-RBM，Miscellaneous等，值得学习。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[视频]《Neural networks class - Université de Sherbrooke》http://t.cn/8s4WOeb 超棒的神经网络课程，深入浅出介绍深度学习，由Hugo Larochelle（Yoshua Bengio的博士生，Geoffrey Hinton之前的博士后）主讲，强烈推荐！ 云:http://t.cn/RA78nK5 (92节已全部搬至国内，希望对大家有帮助)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://quantombone.blogspot.com/2015/01/from-feature-descriptors-to-deep.html&quot;&gt;From feature descriptors to deep learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://simonwinder.com/2015/01/what-is-deep-learning/&quot;&gt;What is Deep Learning?&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://markus.com/deep-learning-101/&quot;&gt;Deep Learning 101&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&quot;&gt;A Deep Learning Tutorial: From Perceptrons to Deep Networks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.iro.umontreal.ca/~bengioy/dlbook/&quot;&gt;deep learning book. by Yoshua Bengio&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~tijmen/csc321/&quot;&gt;Introduction to Neural Networks and Machine Learning by hinton&lt;/a&gt; &lt;a href=&quot;http://www.cs.toronto.edu/~tijmen/csc321/lecture_notes.shtml&quot;&gt;Lecture notes&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[文章]《Why does Deep Learning work?》http://t.cn/RwYyN5J “Multilayer Neural Networks are just Spin Glasses”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://weibo.com/p/1001603799166017998138&quot;&gt;谷歌科学家、Hinton亲传弟子Ilya Sutskever的深度学习综述及实际建议&lt;/a&gt; 比较喜欢其中关于tricks的建议：包括data, preprocessing, minibatches, gradient normalization, learning rate, weight initialization, data augmentation, dropout和ensemble。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.ee.ucl.ac.uk/sahd2014/resources/LeCun.pdf&quot;&gt;LeCun：The Unreasonable Effectiveness of Deep Learning&lt;/a&gt; LeCun做的300+页的深度学习slides，太棒了！毋需多做介绍，单看标题、作者应该就能作出判断——看看看，必须的！&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://colah.github.io/posts/2015-01-Visualizing-Representations/&quot;&gt;Visualizing Representations: Deep Learning and Human Beings&lt;/a&gt; 利用深度学习和维数约减，可以对整个Wikipedia进行可视化，文中结合Wikipedia训练得出的例子，全面介绍了深度学习、词向量、段落向量、翻译模型以及深度学习可视化方面的知识，理论结合实践，实属不可多得的好文。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8775360&quot;&gt;深度学习-笔记整理系列1-8&lt;/a&gt;，&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/9993371&quot;&gt;link2&lt;/a&gt; 使用自下向上非监督学习（就是从底层开始，一层一层的往顶层训练）；自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调）。还介绍了Autoencoder，SparseCoding，Restricted Boltzmann Machine，Deep BeliefNetworks，CNN等模型。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/RZ8Sqe6&quot;&gt;博文“A Brief Overview of Deep Learning”&lt;/a&gt; 有见解有福利。一些技术总结得不错，例如Practice Advice，有很多干货，谁用谁知道…… 文后还有Bengio的点评及与网友的互动讨论。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.bammf.org&quot;&gt;Bay Area Multimedia Forum&lt;/a&gt; 邓力，贾扬清，Ronan Collobert, Richard Socher 讲用深度学习处理语音、文本和图像。有slides有视频。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;&quot;&gt;Neural network with numpy&lt;/a&gt; Python下(只)用numpy写神经网络，不错的开始 &lt;a href=&quot;https://github.com/FlorianMuellerklein/Machine-Learning/blob/master/BackPropagationNN.py&quot;&gt;github code&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://techjaw.com/2015/02/21/googles-large-scale-deep-neural-networks-project-greg-corrado/&quot;&gt;Google’s Large Scale Deep Neural Networks Project, Greg Corrado&lt;/a&gt; Google的大规模分布式DNN介绍 &lt;a href=&quot;http://pan.baidu.com/s/1kTl76AV&quot;&gt;slide&lt;/a&gt; &lt;a href=&quot;http://pan.baidu.com/s/1qWmJrSo&quot;&gt;视频&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;《Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning》http://t.cn/Rw981My 做深度学习选择和使用GPU的一些建议&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对深度学习历史好奇的朋友, 推荐 “The Believers - The hidden story behind the code that runs our lives” http://t.cn/RwCj0wJ “Retrospectively, it was a just a question of the amount of data and the amount of computations,” Hinton says. http://t.cn/RwNHl6u&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://neuralnetworksanddeeplearning.com&quot;&gt;Neural Networks and Deep Learning&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Why does Deep Learning work? &lt;a href=&quot;http://t.cn/RAieIie&quot;&gt;part 1&lt;/a&gt; &lt;a href=&quot;http://t.cn/RAxtm8o&quot;&gt;part 2&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deeplearing-in-nlp&quot;&gt;Deeplearing in NLP综述&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/77709/&quot;&gt;深度学习、自然语言处理和表征方法&lt;/a&gt; &lt;a href=&quot;https://github.com/colah/NLP-RNNs-Representations-Post/blob/master/index.md&quot;&gt;English version&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;单隐层神经网络有一个普适性（universality）：给予足够的隐结点，它可以估算任何函数。普适性的真正意义是：一个网络能适应任何你给它的训练数据。这并不代表插入新的数据点的时候它能表现地很理想。&lt;/li&gt;
      &lt;li&gt;在深度学习工具箱里，把从任务A中学到的好表征方法用在任务B上是一个很主要的技巧。根据细节不同，这个普遍的技巧的名称也不同，如：预训练（pretraining），迁移学习(transfer learning)，多任务学习(multi-task learning)等。这种方法的好处之一是可以从多种不同数据中学习特征表示。&lt;/li&gt;
      &lt;li&gt;共享嵌入是一个非常让人兴奋的研究领域，它暗示着为何深度学习中这个注重表征方法的角度是如此的引人入胜。它目前被应用在机器翻译，ImageCaptioning。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;imagenet-classification&quot;&gt;ImageNet classification&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://arxiv.org/pdf/1502.03167v1.pdf&quot;&gt;Googles breakthrough paper shows 10*faster neural nets, and beats a human&lt;/a&gt; Google的最新论文，用”batch normalization”在ImageNet上得到4.82%( top-5 error)，训练速度也大大加快。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1502.01852&quot;&gt;Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification&lt;/a&gt; 微软所创建的基于深度卷积神经网络系统首次在ImageNet图像分类上超越人类，实现4.94% top-5 test error。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-caption-generation&quot;&gt;Image Caption Generation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1502.03044&quot;&gt;Show, Attend and Tell: Neural Image Caption Generation with Visual Attention&lt;/a&gt; 基于视觉焦点用LSTM自动生成图像内容描述。
来自Yoshua Bengio教授团队（22 pages，8页正文+n多附图），文中报道的结果比之前Microsoft、Google的结果更好。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://pdollar.wordpress.com/2015/01/21/image-captioning/&quot;&gt;Image Captioning&lt;/a&gt;  来自于微软的一篇博文，介绍了image caption的最近进展。图像标题生成小综述，文中引用了另一篇进展综述性文章《Rapid Progress in Automatic Image Captioning》http://t.cn/Rzzk2H3 ，列举出最有影响和代表性的进展和成果(论文)，并从数据集、验证(评价)和下一步怎么走三方面进行了讨论，观点很有代表性&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;http://t.cn/RZdBZEe&quot;&gt;Top Microsoft Machine Learning Posts of 2014&lt;/a&gt; 微软14年最佳博文：图像自动描述生成的飞速进展、机器学习欢乐多、Azule ML为用户带来变革、机器学习与文本分析、微软机器学习20年、Vowpal Wabbit快速学习、什么是机器学习、NIPS14机器学习趋势、机器学习与机器视觉等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[视频]《Automated Image Captioning with ConvNets and Recurrent Nets》http://t.cn/RwXX7zY Stanford的Andrej Karpathy两周前在SF ML meetup上的报告，基于ConvNets和Recurrent Nets的图像标题自动生成，推荐 云:http://t.cn/RwXXQ07&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[视频]《Deep Learning at Flickr》http://t.cn/RwEqZ5U 介绍深度学习在Flickr的应用，主要是图像标签自动提取 云:http://t.cn/RwEqCi7&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[文章]《One Image Is Worth 1,000 Labels》http://t.cn/RwE0Koi 讨论目前基于深度学习的图片自动标注(类别性描述)在应用方面的局限&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rnn-lstm&quot;&gt;RNN&amp;amp; LSTM&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://xxx.tau.ac.il/abs/1502.02367&quot;&gt;Gated Feedback Recurrent Neural Networks&lt;/a&gt;  又有人设计新的RNN了，这回Cho和Bengio都在．这回介绍的GF-RNN说是能比以前Deep RNN的都好。明摆着说LSTM嘛。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/Rww4fbV&quot;&gt;论文 Scaling Recurrent Neural Network Language Models》(2015) W Williams, N Prasad, D Mrva&lt;/a&gt; 讨论如何使用GPU训练大型RNN，以及#RNN##语言模型#(RNNLM)在进行扩展时模型大小、训练集规模和运算开销方面的问题；使用维基和新闻语料训练的大规模RNNLM效果明显。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/RZNfoLt&quot;&gt;Passage：用RNN做文本分析的python库&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://nikhilbuduma.com/2015/01/11/a-deep-dive-into-recurrent-neural-networks/&quot;&gt;深入讨论RNN&lt;/a&gt;  &lt;a href=&quot;http://www.csdn.net/article/2015-01-28/2823747&quot;&gt;译文&lt;/a&gt;非常好的讨论递归神经网络的文章，覆盖了RNN的概念、原理、训练及优化等各个方面内容，强烈推荐！本文作者Nikhil Buduma，也是《Deep Learning in a Nutshell》的作者。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;深度RNN/LSTM用于结构化学习 0)序列标注&lt;a href=&quot;http://t.cn/RZZs9Io&quot;&gt;Connectionist Temporal Classification ICML06&lt;/a&gt; 1)机器翻译&lt;a href=&quot;http://t.cn/RZZs9Jk&quot;&gt;Sequence to Sequence NIPS14&lt;/a&gt; 2)成分句法&lt;a href=&quot;http://t.cn/RZZs9Ia&quot;&gt;GRAMMAR AS FOREIGN LANGUAGE&lt;/a&gt; 再次用到窃取果实distilling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[视频]《General Sequence Learning using Recurrent Neural Networks》http://t.cn/RwiEI9d Alec Radford讲的用RNN做文本序列分析(学习) 云:http://t.cn/RwinOCb Alec Radford的Passage:http://weibo.com/1402400261/BFVLkxtfw&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://people.idsia.ch/~juergen/lstm/index.htm&quot;&gt;幻灯 Long Short-Term Memory: Tutorial on LSTM Recurrent Networks&lt;/a&gt;  J. Schmidhuber的LSTM递归网络教程&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[幻灯] 《Theano and LSTM for Sentiment Analysis》http://t.cn/RwofVaF Next.ML 2015上用Theano和LSTM做情感分析的报告幻灯和练习 GitHub:http://t.cn/RwofqDC 云:http://t.cn/Rwofo4i&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;最近很火的两篇文章，Neural Turing Machines和Learning to Execute，都讲到用LSTM RNN做sequence copy，来测试网络保持长时记忆的能力。sequence copy到底怎么定义为一个supervised learning任务呢？和机器翻译一样吗？&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;特别喜欢Long-short-term-memory(LSTM) architecture, it explicitly models ‘forgetting’ in sequence processing. LSTM是gated RNNs 的典型代表, 它部分解决了 long-term dependency 的问题, Alex Graves 在 LSTM 上较有研究, 读读他的paper: deep RNN for speech recognition http://t.cn/RZt9knn&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stanford推出利用parsing的树状LSTM, 在Stanford Sentiment Treebank上表现还凑合，句子相似度计算上不错http://t.cn/RwRLwvx&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cnn&quot;&gt;CNN&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://dataunion.org/?p=5395&quot;&gt;深度学习：CNN的反向求导及练习&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Character-based CNN。&lt;a href=&quot;http://arxiv.org/abs/1502.01710&quot;&gt;论文 Text Understanding from Scratch 2015 Xiang Zhang, Yann LeCun&lt;/a&gt;  深度学习在NLP领域最新进展！使用temporal ConvNets对大规模文本语料进行学习，在本体分类、情感分析、文本分类任务中取得了“astonishing performance”，不依赖任何语言知识，中英文均适用。必读！&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1404.2188&quot;&gt;论文 A Convolutional Neural Network for Modelling Sentences. Nal Kalchbrenner等&lt;/a&gt; 用动态卷积神经网络(DCNN)对句子进行语义建模，该方法不依赖解析树也不受语种限制，效果也很明显，推荐学习。其项目主页上http://t.cn/RZd9HOE 提供了源码(Matlab) 云:http://t.cn/RZdCx1o&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;用CNN网络实现人脸关键点检测 http://t.cn/RwSwAct&lt;/td&gt;
          &lt;td&gt;教你用Theano、Lasagne等工具在python里训练网络检测人脸关键点。跟什么MNIST识别数字相比，这个任务还算是更接近实际问题的复杂程度了。PS：用Lasagne来命名深度网络库还真是吃货本质啊&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://yann.lecun.com/exdb/lenet/index.html&quot;&gt;Mnist demos&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;普通神经网络做图像识别的缺点：
1. 一般要得到较好的训练效果，隐层数目不能太少，当图片大的时候，需要的权值会非常多。
2. 对平移、尺度变化敏感（比如数字偏左上角，右下角时即识别失败）。
3. 图片在相邻区域是相关的，而这种网络只是一股脑把所有像素扔进去，没有考虑图片相关性。&lt;/p&gt;

&lt;p&gt;而CNN通过local receptive fields（感受野），shared weights（共享权值），sub-sampling（下采样）概念来解决上述三个问题。&lt;a href=&quot;&quot;&gt;Gradient-Based Learning Applied to Document Recognition &lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/stdcoutzyx/article/details/41596663&quot;&gt;卷积神经网络入门&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/cnn_param_number.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;计算卷积神经网络的参数个数，如上图所示，输入是4个通道，输出是2个通道，那么参数个数=2&lt;em&gt;(4&lt;/em&gt;2*2 + 1)。需要注意的是，输入四个通道上每个通道对应一个卷积核，如上图W参数所示。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[论文]《Learning a Deep Convolutional Network for Image Super-Resolution》C Dong, CC Loy, K He, X Tang (2014) 用CNN做单副图像升超分辨率(SR)，轻量架构，性能高，可支持在线应用 PDF:http://t.cn/RwrNfBB 源码:http://t.cn/RwrNMNa Kaiming 云:http://t.cn/RwrpUKv&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;Word2vec&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;[问答]《What are some interesting Word2Vec results?》http://t.cn/RZrOfYp Quora上的主题，讨论Word2Vec的有趣应用，Omer Levy提到了他在CoNLL2014最佳论文里的分析结果和新方法（稍后单独推荐），Daniel Hammack给出了找特异词的小应用并提供了(Python)代码http://t.cn/zQgLQ20&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ensemble of Generative and Discriminative Techniques for Sentiment Analysis of Movie Reviews。&lt;a href=&quot;https://github.com/mesnilgr/iclr15&quot;&gt;code，include sentence2vec&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;隐含主题模型LDA的学习过程可为文档每个词分配隐含主题，我组本科生刘扬同学利用LDA为词汇提供的补充信息，提出topical word embeddings，在词汇相似度计算和文本分类上得到一些有趣的结果。&lt;a href=&quot;https://github.com/largelymfs/topical_word_embeddings&quot;&gt;github code&lt;/a&gt;，&lt;a href=&quot;http://nlp.csai.tsinghua.edu.cn/~lzy/publications/aaai2015_twe.pdf&quot;&gt;论文Topical Word Embeddings&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/idio/wiki2vec&quot;&gt;Wiki2Vec: Generating Vectors for DBpedia Entities via Word2Vec and Wikipedia Dumps&lt;/a&gt; 从维基百科Dumps生成Word2Vec向量的工具，包括词向量和主题向量&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://andyljones.tumblr.com/post/111299309808/why-word2vec-works&quot;&gt;Why word2vec works&lt;/a&gt; word2vec的工作原理&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www-personal.umich.edu/~ronxin/pdf/w2vexp.pdf&quot;&gt;word2vec Parameter Learning Explained&lt;/a&gt; word2vec梯度推导详解&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[文章]《Movie Review Sentiment Analysis With Word2Vec, DBNs and RNTN》http://t.cn/RwNuyKP Java里用word2vec做电影评论情感分析的例子&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;以word2vec为人所知的前谷歌脑计划研究科学家现在Facebook人工智能实验室的Tomas Mikolov在COLING 2014给的Tutorial 【Using Neural Networks for Modelling and Representing Natural Languages】CBOW，Skip-gram，Negative sampling http://t.cn/RZTjakc Mikolov博士毕业于捷克的布尔诺科技大学&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我发现word2vec算出来的相似度并没有一个统一的衡量方式，找某个词topN similar是没问题的，但假设有两个pair，并不能因为pair1的word2vec similarity高就说pair1比pair2更相似，因此也没法设一个threshold去取舍这些pairs。
phunter_lau：word2vec词之间的similarity我的理解是更像是关联度而不是相似度，也就是他们常常一起出现，所以引申出来他们有某种相似性&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[论文]《Random Walks on Context Spaces: Towards an Explanation of the Mysteries of Semantic Word Embeddings》(2015) S Arora, Y Li, Y Liang等 http://t.cn/RwHPhwf 用对数线性生成模型为word2vec等word embedding方法寻求合理解释。简化版解释一篇:《Why word2vec works》http://t.cn/Rw6jNo6&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[IPN]《Document classification by inversion of distributed language representations》http://t.cn/RwBr14V 基于Gensim(word2vec)的(评论)文档分类实例&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;中英文维基百科语料上的Word2Vec实验: 最近利用gensim word2vec模块在中英文维基百科语料上分别测试了一下word2vec，记录一下实验的过程，欢迎观摩 http://t.cn/Rwd87KO&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;加强学习&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;DeepMind在Nature上发表《Human-level control through deep reinforcement learning》http://t.cn/Rw0ZSW0 基于reinforcement learning让算法学习打游戏，源码:http://t.cn/Rw084MA ，http://t.cn/RwORUqX 对相关文章和工作进行了整理，DeepMind的专访http://t.cn/RwOR5EG 云:http://t.cn/RwORY9h&lt;/p&gt;

    &lt;p&gt;论文PDF全文可从这里下：http://t.cn/RwOBdZ7&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;生物学&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Yoshua Bengio团队（Bengio一作）新作：Towards Biologically Plausible Deep Learning，尝试在Deep Learning与生物学观察（Spike-Timing- Dependent Plasticity）之间建立联系。寻找或探索机器学习的生物学解释，感觉很有意义。http://t.cn/RwCfROu&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;语音识别&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;[文章]《Deep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning》http://t.cn/RwHfNKN GPU加速的大规模深度学习，用于语音识别，来自百度硅谷AI实验室&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 23 Feb 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/02/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/02/23/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0.html</guid>
        
        
      </item>
    
      <item>
        <title>文献综合阅读</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;知识总结&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;微博上关于机器学习的相关讨论： 微博收藏（机器学习探讨）（二） - LinJM-机器视觉 - 博客频道 - CSDN.NET 1.0 关于深度学习与工程师的讨论； 2.0 小数据VS大数据 by BAOJIE； 3.0 @陈天奇怪：cxxnet和大规模深度学习； 4.0 Eric Xing(CMU教授)的DNN-discussion …… http://t.cn/RAA8rwc&lt;/li&gt;
  &lt;li&gt;总结的很棒！强烈推荐。其他两篇 机器学习代码与工具（一）http://t.cn/RA22Jhv 机器学习课程与论文（三）http://t.cn/RA22JPs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;图像视觉&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/morewindows/article/details/8225783&quot;&gt;OpenCV入门指南&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://quantombone.blogspot.com/2015/01/from-feature-descriptors-to-deep.html&quot;&gt;From feature descriptors to deep learning: 20 years of computer vision&lt;/a&gt; 从特征描述子到深度学习——机器视觉20年回顾。通俗易懂，回顾了很多特征描述子的内容，也介绍了很多计算机视觉、机器学习特别是深度学习方面的大牛。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://t.cn/RZkbwoz&quot;&gt;图像处理中的全局优化技术&lt;/a&gt; 最近打算好好学习一下几种图像处理和计算机视觉中常用的 global optimization (或 energy minimization) 方法，这里总结一下学习心得。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/carson2005/article/details/9502053&quot;&gt;Retinex算法详解&lt;/a&gt; - 计算机视觉小菜鸟的专栏 - 博客频道 - CSDN.NET&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;本团队雕琢多年的人脸检测库现以MIT协议发布 &lt;a href=&quot;https://github.com/ShiqiYu/libfacedetection&quot;&gt;github code&lt;/a&gt; 供商业和非商业无限制使用,包含正面和多视角人脸检测两个算法.优点:速度快(OpenCV haar+adaboost的2-3倍), 准确度高 (FDDB非公开类评测排名第二），能估计人脸角度. 例子看下图. 希望能帮助到有需要的个人和公司。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.guokr.com/article/439945/&quot;&gt;计算机视觉：让冰冷的机器看懂多彩的世界&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[论文]《FaceNet: A Unified Embedding for Face Recognition and Clustering》http://t.cn/Rwg398R Google对Facebook DeepFace的有力回击—— FaceNet，在LFW(Labeled Faces in the Wild)上达到99.63%准确率(新纪录)，FaceNet embeddings可用于人脸识别、鉴别和聚类&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/sciencefans/p/4394861.html&quot;&gt;人脸识别技术大总结(1)：Face Detection &amp;amp; Alignment&lt;/a&gt; 介绍人脸识别的四大块：Face detection, alignment, verification and identification(recognization)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;互联网金融&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://queue.acm.org/detail.cfm?id=2534976&quot;&gt;文章 Online Algorithms in High-frequency Trading - The challenges faced by competing HFT algorithms》2013&lt;/a&gt; 介绍高频交易(HFT)中的在线学习算法，重点解决流动性估计、波动性估计和线性回归问题，HFT算法简单了解可参考&lt;a href=&quot;http://www.zhihu.com/question/23667442&quot;&gt;知乎主题-高频交易都有哪些著名的算法&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/22221540&quot;&gt;对于 Quant 来说， Financial Modeling 和传统的机器学习方法有什么联系和区别？&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/27420308/answer/38632429&quot;&gt;机器学习（非传统统计方法如回归）到底在量化金融里哪些方面有应用？&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;section-3&quot;&gt;搜索&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;信息检索排序模型BM25(Besting Matching)。1）从经典概率模型演变而来 2）捕捉了向量空间模型中三个影响索引项权重的因子：IDF逆文档频率；TF索引项频率；文档长度归一化。3）并且含有集成学习的思想：组合了BM11和BM15两个模型。4）作者是BM25的提出者和Okapi实现者Robertson http://t.cn/RwRxieT&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;博客推荐与面试&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;《Frequently updated Machine Learning blogs》http://t.cn/RwbHZpy 活跃机器学习博客推荐，真有点怀念Google Reader呢&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;《面试经验分享之机器学习、大数据问题》如今，好多机器学习、数据挖掘的知识都逐渐成为常识，要想在竞争中脱颖而出，就必须做到：保持学习热情，关心热点，深入学习，会用，也要理解，在实战中历练总结等等。http://t.cn/RzMtL3j（来自： Blog of 太极雪 ）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://chuansong.me/n/306480&quot;&gt;FLAGBR 面经+offer&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;『机器学习&amp;amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理） - tornadomeet - 博客园』http://t.cn/zRoZPzP&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/stdcoutzyx/article/details/42041947&quot;&gt;北美公司面试经验笔记&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-5&quot;&gt;其他推荐资料&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://breezedeus.github.io/2015/01/31/breezedeus-review-for-year-2014-tech.html&quot;&gt;世纪佳缘用户推荐系统的发展历史&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;“总结、温习，这两点让人成长。而不是你走得有多快！”&lt;/li&gt;
      &lt;li&gt;天真的算法年：item-based kNN。推荐以前看过的item的相似item。可逆（Reciprocal）推荐算法，是什么东西？&lt;a href=&quot;http://search.aol.com/aol/search?s_it=topsearchbox.search&amp;amp;v_t=opensearch&amp;amp;q=Reciprocal+recommendation&quot;&gt;Reciprocal recommendation&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;技术为产品服务，而不是直接面向用户；数据质量是地基，保证好的质量很不容易；如何制定正确的优化指标真的很难；业务理解 &amp;gt; 工程实现；数据 &amp;gt; 系统 &amp;gt; 算法；快速试错；&lt;/li&gt;
      &lt;li&gt;Dirichlet Process 和 Dirichlet Process Mixture&lt;/li&gt;
      &lt;li&gt;Alternating Direction Method of Multipliers(ADMM)&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://breezedeus.github.io/2014/11/19/breezedeus-feature-mining-gbdt.html&quot;&gt;利用GBDT模型构造新特征&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://breezedeus.github.io/2014/11/20/breezedeus-feature-hashing.html&quot;&gt;特征哈希（Feature Hashing）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;不平衡数据的抽样方法。参考文献：William Fithian, Trevor Hastie, Local Case-Control Sampling Efficient Subsampling in Imbalanced Data Sets, 2014.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.douban.com/note/484853135/&quot;&gt;世纪佳缘推荐系统之我见&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;明确推荐评价指标：对于婚恋推荐系统来说，最核心的指标无外乎付费的转换率&lt;/li&gt;
          &lt;li&gt;我们倒着来推，把问题转换为识别出最愿意付费的那些用户，然后找到这些用户感兴趣的用户，通过产品引导让这些用户发信&lt;/li&gt;
          &lt;li&gt;能不能从数据跳出来对产品提出一些创意性改进从而产生的产品模式和收费模式的变革。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.wsdm-conference.org/2015/wp-content/uploads/2015/02/WSDM-2015-PE-Leskovec.pdf&quot;&gt;New Directions in Recommender Systems&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.douban.com/note/484692347/&quot;&gt;飞林沙-读后总结&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;需要理解 可替换 和 可补充，这两种推荐形式。&lt;/li&gt;
      &lt;li&gt;怎样生成替代品的推荐理由，应该是更好，而不是他们包含同一关键词&lt;/li&gt;
      &lt;li&gt;推荐一整套装备&lt;/li&gt;
      &lt;li&gt;Inferring Networks from Opinions阅读总结：
        &lt;ul&gt;
          &lt;li&gt;Product Graph：Building networks from product text
            &lt;ul&gt;
              &lt;li&gt;Understand the notions of substitute and complement goods&lt;/li&gt;
              &lt;li&gt;Generate explanations of why certain products are preferred&lt;/li&gt;
              &lt;li&gt;Recommends baskets of related items&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;learn x and y are related?
            &lt;ul&gt;
              &lt;li&gt;Attempt 1: Text features；缺点：High-dimensional，Prone to overfitting，Too fine-grained&lt;/li&gt;
              &lt;li&gt;Attempt 2: Features from Topics。也就是把第一种方法，用topic vector替换，相当于降维了。&lt;/li&gt;
              &lt;li&gt;Attempt 3: Learn ‘good’ topics。Learn to discover topics that explain the graph structure；
                &lt;ul&gt;
                  &lt;li&gt;Idea: Learn both simultaneously；we want to learn to project documents (reviews) into topic space such that related products are nearby；&lt;/li&gt;
                  &lt;li&gt;Combining topic models with link prediction；topic和link利用一个目标函数，一起训练。&lt;/li&gt;
                  &lt;li&gt;Issue 1: Relationships we want to learn are not symmetric；Solution: We solve this issue by learning “relatedness” in addition to “directedness”&lt;/li&gt;
                  &lt;li&gt;Issue 3: The model has a too many parameters；Solution: Product hierarchy；Associate each node in the category tree with a small number of topics&lt;/li&gt;
                  &lt;li&gt;整个模型用EM算法来求解，类似于PLSA的EM算法。&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recommender Systems，Alex Smola 阅读笔记
    &lt;ul&gt;
      &lt;li&gt;Neighborhood methods
        &lt;ul&gt;
          &lt;li&gt;Collaborative filtering；User-based (item base is smaller than user or changes rapidly)；Item-based (user base is small)；&lt;/li&gt;
          &lt;li&gt;Normalization/Bias; rate bias-&amp;gt; bui = μ(global) + bu(user bias) + bi(item bias);
  &lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/cf_formula.png&quot; alt=&quot;&quot; /&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/item_similarity.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Matrix Factorization
        &lt;ul&gt;
          &lt;li&gt;SVD，常用优化方法：SGD，alternating optimization；问题是Overfitting without regularization，特别是fewer reviews than dimensions&lt;/li&gt;
          &lt;li&gt;Risk Minimization。利用Alternating least squares，比较适合MR。
  &lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/matrix_factorization_risk.png&quot; alt=&quot;&quot; /&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/zzbased/zzbased.github.com/master/_posts/images/matrix_factorization_risk_addbias.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;优化方法：Add bias，who rated what， temporal effects … P63&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Theoretical Motivation
        &lt;ul&gt;
          &lt;li&gt;Rating matrix is (row, column) exchangeable&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Ranking and Session Modeling
        &lt;ul&gt;
          &lt;li&gt;Independent click model&lt;/li&gt;
          &lt;li&gt;Logistic click model。Exponential family model for click; user looks at all&lt;/li&gt;
          &lt;li&gt;Sequential click model; User traverses list&lt;/li&gt;
          &lt;li&gt;Skip click model&lt;/li&gt;
          &lt;li&gt;Context skip click model&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Features
        &lt;ul&gt;
          &lt;li&gt;social network = friendship + interests&lt;/li&gt;
          &lt;li&gt;Latent dense (Bayesian Probabilistic Matrix Factorization)&lt;/li&gt;
          &lt;li&gt;Latent sparse (Dirichlet process factorization)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hashing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://breezedeus.github.io/2012/11/01/breezedeus-yuanquan-etao.html&quot;&gt;个性化推荐技术#总结-袁全&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;相关性推荐，点击数据更有用；补充性推荐，购买数据更有用；要根据用户行为意图选择不同的推荐方法。&lt;/li&gt;
      &lt;li&gt;对于不同种类的产品，当用户处在同一购物流程时，其理想的相关性推荐/补充性推荐的概率也差别很大。&lt;/li&gt;
      &lt;li&gt;Mixture Logistic Regression&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://breezedeus.github.io/2012/11/10/breezedeus-jiangshen.html&quot;&gt;面向广告主的推荐，江申@百度&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;技术目标要正确；譬如对于拍卖词推荐，其数学目标的烟花过程为：推荐最相关的词-&amp;gt;推荐广告主采用率最高的词-&amp;gt;推荐采用率最高且产生推广效果最佳的词。&lt;/li&gt;
      &lt;li&gt;在拍卖词推荐中主要涉及到三种模型：相关性模型、采用率模型和推广效果模型。&lt;/li&gt;
      &lt;li&gt;负反馈：按照item已经对user展示的次数指数级降低其权重，避免同一个item多次重复被展示给一个用户。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://breezedeus.github.io/2012/11/12/breezedeus-wenguozhu.html&quot;&gt;个性化推荐技术#总结 稳国柱@豆瓣&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;电影推荐：首先把电影按照电影标签进行分组（比如分成动作片，剧情片等）；然后在每个组里面使用CF算法产生推荐结果；最后把每组中获得的推荐按照加权组合的方式组合在一块。&lt;/li&gt;
      &lt;li&gt;图书推荐：图书有一定的阶梯性，在大部分的场合，我们需要的并不是与自己相似的用户的推荐，而是与自己相似的专家的推荐。&lt;/li&gt;
      &lt;li&gt;电台的音乐推荐：必须使用一个算法系统（其中包含多个算法）来针对不同的用户进行不同的算法调度&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.douban.com/note/472267231/&quot;&gt;年终总结 &amp;amp; 算法数据的思考 by 飞林沙&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.aszxqw.com/work/2014/06/01/tuijian-xitong-de-nadianshi.html&quot;&gt;推荐系统的那点事&lt;/a&gt; 分析了推荐系统中使用算法的误区，确实规则带来的好处简单有效。 当一个做推荐系统的部门开始重视【数据清理，数据标柱，效果评测，数据统计，数据分析】这些所谓的脏活累活，这样的推荐系统才会有救。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;WSDM2015 上传了Michaol Franklin和Thorsten Joachims的主题报告slides http://t.cn/R7Jyy0g 还有Jure Leskovec和Tushar Chandra的实践与经验报告 slides &lt;a href=&quot;http://www.wsdm-conference.org/2015/practice-and-experience-talks/&quot;&gt;Practice and Experience Talks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;[文章]《Computing Recommendations at Extreme Scale with Apache Flink and Google Compute Engine》http://t.cn/RZemQe9 Flink实例！用Flink和GAE做面向大规模数据集的协同推荐，从中可看出Flink的巨大应用潜力，文中引用的材料值得一读（作者说了，细节文章即将推出敬请期待，感兴趣请持续关注）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;[幻灯]《Recommender Systems: Super Overview》http://t.cn/R7WtFwY 来自Netflix的Xavier Amatriain在Summer School 2014 @ CMU上长达4小时的报告，共248页，是对推荐系统发展的一次全面综述，其中还包括Netflix在个性化推荐方面的一些经验介绍，强烈推荐! 云盘:http://t.cn/RZuLoSS&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;【干货丨美团推荐算法实践：机器学习重排序模型成亮点】本文介绍了美团网推荐系统的构建和优化过程中的一些做法，包括数据层、触发层、融合过滤层和排序层五个层次，采用了HBase、Hive、storm、Spark和机器学习等技术。两个优化亮点是将候选集进行融合与引入重排序模型。 http://t.cn/RZrgB5u&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://tech.meituan.com/machinelearning-data-feature-process.html&quot;&gt;美团推荐团队-机器学习中的数据清洗与特征处理综述&lt;/a&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://benanne.github.io/2014/08/05/spotify-cnns.html&quot;&gt;文章-Recommending music on Spotify with deep learning&lt;/a&gt; 基于作者的实习经历讲Spotify的音乐推荐，内容涉及：协同过滤、基于内容的推荐、基于深度学习的品味预测、convnets规模扩展、convnets的学习内容、推荐的具体应用等
    &lt;ul&gt;
      &lt;li&gt;Collaborative filtering：content-agnostic（与内容无关的），容易推荐popular items。另外，new and unpopular songs cannot be recommended，即cold-start problem。&lt;/li&gt;
      &lt;li&gt;Content-based：tags, artist and album information, lyrics, text mined from the web (reviews, interviews, …), and the audio signal itself（e.g. the mood of the music）。&lt;/li&gt;
      &lt;li&gt;Predicting listening preferences with deep learning。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;【推荐系统中所使用的混合技术介绍】http://t.cn/8sKdQFq 系统架构层面一般使用多段组合混合推荐框架，算法层面则使用加权型混合推荐技术，包括LR、RBM、GBDT系列。此外还介绍分级型混合推荐技术，交叉调和技术，瀑布型混合方法，推荐基础特征混合技术，推荐模型混合技术，整体式混合推荐框架等。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 23 Feb 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/02/23/%E6%96%87%E7%8C%AE%E7%BB%BC%E5%90%88%E9%98%85%E8%AF%BB.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/02/23/%E6%96%87%E7%8C%AE%E7%BB%BC%E5%90%88%E9%98%85%E8%AF%BB.html</guid>
        
        
      </item>
    
      <item>
        <title>系统知识总结</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;系统设计&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Optimal Space-time Tradeoffs for Inverted Indexes，Github http://t.cn/RZgGiiN 倒排的最新压缩设计，作者是去年创新索引压缩算法Partitioned Elias-Fano的发明人，今年继续给出各种情形下的最佳选择，http://t.cn/RZgGiiC &lt;a href=&quot;http://www.di.unipi.it/~ottavian/files/wsdm15_index.pdf&quot;&gt;论文 Optimal Space-time Tradeoffs for Inverted Indexes&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://fex.baidu.com/blog/2014/04/traffic-hijack/&quot;&gt;流量劫持是如何产生的&lt;/a&gt; 流量劫持，这种古老的攻击沉寂了一段时间后，最近又开始闹的沸沸扬扬。众多知名品牌的路由器相继爆出存在安全漏洞，引来国内媒体纷纷报道。只要用户没改默认密码，打开一个网页甚至帖子，路由器配置就会被暗中修改。互联网一夜间变得岌岌可危。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://network.51cto.com/art/201103/252335.htm&quot;&gt;输入facebook的URL按下回车后究竟发生了什么&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.infoq.com/cn/articles/cache-coherency-primer&quot;&gt;缓存一致性 Cache Coherency&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/dolphin0520/archive/2011/08/25/2153720.html&quot;&gt;二叉树的非递归遍历&lt;/a&gt; 利用stack来实现非递归遍历。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.grpc.io/&quot;&gt;Google RPC框架&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;https://github.com/google/protobuf/wiki/Third-Party-Add-ons&quot;&gt;RPC Implementations&lt;/a&gt; 这里面有众多RPC框架的实现，有各种语言的版本。
百度的两个版本：&lt;a href=&quot;https://github.com/Baidu-ecom/Jprotobuf-rpc-socket&quot;&gt;Jprotobuf-rpc-socket&lt;/a&gt;，&lt;a href=&quot;https://github.com/BaiduPS/sofa-pbrpc&quot;&gt;sofa-pbrpc&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;编程语言&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.iteye.com/magazines/130&quot;&gt;编程精华资源-ITeye优秀专栏-大汇总&lt;/a&gt;
Java学习，Java框架，Web 前端，编程语言，开源项目研究，编程经验之谈，数据库，设计模式，项目管理，移动开发，云计算与大数据等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://coolshell.cn/articles/9104.html&quot;&gt;sed 简明教程&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.vaikan.com/bash-scripting/&quot;&gt;bash脚本15分钟进阶&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2015/02/make.html&quot;&gt;Make 命令教程 - 阮一峰的网络日志&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios&quot;&gt;IOS&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;@李锦发 整理的《iOS 学习资料整理》为 iOS 初学者所准备, 旨在帮助 iOS 初学者们快速找到适合自己的学习资料, 节省搜索资料的时间, 更好地规划学习路线, 更准确地定位目前所处的位置。Github直达http://t.cn/RZMNgIt [给力] 也欢迎大家订阅《App开发日报》http://t.cn/RwytoqC 及时获得最新资源推送&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;控制&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zhihu.com/question/26944678&quot;&gt;知乎一个控制类算法的讨论&lt;/a&gt; 应用最广泛的两类控制算法——PID （Proportional Integral Derivative）和 MPC（Model Predictive Control)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sed--awk&quot;&gt;Sed &amp;amp; Awk&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://coolshell.cn/articles/9104.html&quot;&gt;sed 简明教程&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://coolshell.cn/articles/9070.html&quot;&gt;awk 简明教程&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 22 Feb 2015 00:00:00 +0800</pubDate>
        <link>http://yourdomain.com/2015/02/22/%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html</link>
        <guid isPermaLink="true">http://yourdomain.com/2015/02/22/%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93.html</guid>
        
        
      </item>
    
  </channel>
</rss>
