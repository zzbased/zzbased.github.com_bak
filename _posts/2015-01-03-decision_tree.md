---
layout: post
title: "决策树"
description: ""
category:
tags: []
---

## 决策树与GBDT

- [决策树模型组合之随机森林与GBDT](http://cvchina.net/post/107.html)

	[机器学习中的算法(1)-决策树模型组合之随机森林与GBDT link2](http://www.cnblogs.com/LeftNotEasy/archive/2011/03/07/random-forest-and-gbdt.html)

	模型组合与决策树相关的算法比较多，这些算法最终的结果是生成N棵树，这样可以大大的减少单决策树带来的毛病，有点类似于三个臭皮匠等于一个诸葛亮的做法，虽然这几百棵决策树中的每一棵都很简单，但是他们组合起来确是很强大。

- [经典文章 Greedy function approximation : A Gradient Boosting Machine](http://statweb.stanford.edu/~jhf/ftp/trebst.pdf)

- [xgboost - eXtreme Gradient Boosting (GBDT or GBRT) Library, also support distributed learning](https://github.com/tqchen/xgboost)

	并行实现推荐 @陈天奇怪 的xgboost，实际例子见@phunter_lau 最近的文章 http://t.cn/RhKAWac

- [pGBRT: Parallel Gradient Boosted Regression Trees](http://machinelearning.wustl.edu/pmwiki.php/Main/Pgbrt)

- [更多GBDT](http://bigdata.memect.com/?tag=GBDT)

- [决策树 用Python实现了决策树的ID3生成算法和C4.5生成算法](http://www.hankcs.com/ml/decision-tree.html)

- [论文 Understanding Random Forests: From Theory to Practice](http://t.cn/RZBT6Ap)
Louppe, Gilles的博士论文，全面了解随机森林的好材料，推荐！pdf:http://t.cn/RZBTobH 云:http://t.cn/RZBTobT

- [Interpreting random forests](http://blog.datadive.net/interpreting-random-forests/)
