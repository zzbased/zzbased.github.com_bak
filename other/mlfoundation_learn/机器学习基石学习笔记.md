# 机器学习基石 学习笔记

## 第一讲

有用链接：

- [机器学习基石](https://www.coursera.org/course/ntumlone)
- [机器学习技法](https://class.coursera.org/ntumltwo-001/lecture)
- [beader.me笔记](http://beader.me/mlnotebook/)
- [听课笔记douban](http://www.douban.com/doulist/3440234/)
- [mooc学院](http://mooc.guokr.com/course/610/機器學習基石--Machine-Learning-Foundations-/)

f 表示理想的方案
g 表示求解的用来预测的假设
H：假设空间
X：输入
Y：输出
D：训练集合
A：算法

A takes D and H to get g。通过算法A，利用训练集合D，在假设空间H中选择最好的假设g，选择标准是g近似于f。

![](Formalize_the_Learning_Problem.png)

![](Practical_Definition_of_Machine_Learning.png)

## 第二讲

perceptron，感知器。此时h的形式为：h(x) = w*x。感知机（perceptron）是一个线性分类器(linear classifiers），线性分类器的几何表示为：直线，平面，超平面。

![](perceptron.png)

注意H是infinite size；

PLA(perceptron learning algorithm)，PLA A takes linear separable D and perceptrons H to get hypothesis g。

![](perceptron_learning_algorithm.png)

上面，PLA算法如果D不是线性可分的，则PLA始终不能收敛。

![](pocket_algorithm.png)

与简单PLA 的区别：迭代有限次数（提前设定）；随机地寻找分错的数据（而不是循环遍历）；只有当新得到的w 比之前得到的最好的wg 还要好时，才更新wg（这里的好指的是分出来的错误更少）。
由于计算w 后要和之前的wg 比较错误率来决定是否更新wg， 所以pocket algorithm 比简单的PLA 方法要低效。

## 第三讲
reinforcement learning：广告系统，扑克，棋类游戏。
unsupervised learning：聚类，density estimate，异常检测。
semi-supervised learning：人脸识别，医药效果检测；

batch：填鸭式教学；
online：一条一条的教学；
active：sequentialliy问问题；

[Active learning](http://en.wikipedia.org/wiki/Active_learning_(machine_learning))

![](types_of_learning.png)

## 第四讲
机器学习的可行性分析。

- 对于xor问题，perceptron是无解的。所以learning is impossible。如何解决上述存在的问题？ 答：做出合理的假设。

- 霍夫丁不等式(Hoeffding’s Inequality)，下式中v是样本概率；u是总体概率。

![](hoeffding_inequality.png)

- Connection to Learning

![](Connection_to_Learning1.png)

面对多个h 做选择时，容易出现问题。比如，某个不好的h 刚好最初的”准确“ 的假象。
随着h 的增加，出现这种假象的概率会增加。

![](bound_of_baddata.png)

所以，当假设空间有限时（大小为M）时， 当N 足够大，发生BAD sample 的概率非常小。
此时学习是有效的。

![](Statistical_Learning_Flow.png)

## 第五讲

学习的可能性：

1. 假设空间H有限（M），且训练数据足够大，则可以保证测试错误率Eout 约等于训练错误率Ein；
2. 如果能得到Ein 接近于零，根据（1），Eout 趋向于零。

以上两条保证的学习的可能性。

![](chapter5_1.png)

M存在重要的trade-off 思想：
（1）当M 很小，那么坏数据出现的概率非常小（见第四讲分析），学习是有效的；但是由于假设空间过小，我们不一定能找到一个方案，可以使训练误差接近零；
（2）反之，若M 很大，因为choices变多，可能找到合适的方案g使E_in(g)=0，但坏数据出现的概率会变大。

## 第六讲-第七讲

关于VC维，请参考独立文章[VC维的来龙去脉](http://zzbased.github.io/2015/03/07/VC维的来龙去脉.html)